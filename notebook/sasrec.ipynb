{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SASRec SUM Seqemb and userllmemb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (697378, 4)\n",
      "Valid size: (99582, 4)\n",
      "Test size: (203165, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>978300019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>978300103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1     3186       4  978300019\n",
       "1        1     1721       4  978300055\n",
       "2        1     1022       5  978300055\n",
       "3        1     1270       5  978300055\n",
       "4        1     2340       3  978300103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пользователей в обучающем наборе: 6040\n",
      "Количество пользователей в валидационном наборе: 5954\n",
      "Количество пользователей в тестовом наборе: 6040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\redpo\\Desktop\\sasrec-bert4rec-recsys23\\.venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 7.9572, Valid Loss: 7.3264\n",
      "Epoch 2/10, Train Loss: 6.8373, Valid Loss: 6.4886\n",
      "Epoch 3/10, Train Loss: 5.9530, Valid Loss: 5.6703\n",
      "Epoch 4/10, Train Loss: 5.1423, Valid Loss: 4.8559\n",
      "Epoch 5/10, Train Loss: 4.3579, Valid Loss: 4.1741\n",
      "Epoch 6/10, Train Loss: 3.7020, Valid Loss: 3.6275\n",
      "Epoch 7/10, Train Loss: 3.1220, Valid Loss: 3.1844\n",
      "Epoch 8/10, Train Loss: 2.6448, Valid Loss: 2.7998\n",
      "Epoch 9/10, Train Loss: 2.2539, Valid Loss: 2.5705\n",
      "Epoch 10/10, Train Loss: 1.9358, Valid Loss: 2.3089\n",
      "Precision@10: 0.0771\n",
      "Recall@10: 0.7705\n",
      "NDCG@10: 0.7288\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader  # Добавленные импорты\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Параметры\n",
    "max_len = 50        # Определение max_len\n",
    "batch_size = 128    # Определение batch_size\n",
    "\n",
    "# Файлы данных\n",
    "train_file = '../data/source/1_ml-1m_original.part1.inter'\n",
    "valid_file = '../data/source/1_ml-1m_original.part2.inter'\n",
    "test_file = '../data/source/1_ml-1m_original.part3.inter'\n",
    "\n",
    "# Загрузка данных\n",
    "train_data = pd.read_csv(train_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "valid_data = pd.read_csv(valid_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "test_data = pd.read_csv(test_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "\n",
    "print(f'Train size: {train_data.shape}')\n",
    "print(f'Valid size: {valid_data.shape}')\n",
    "print(f'Test size: {test_data.shape}')\n",
    "\n",
    "display(train_data.head())\n",
    "\n",
    "# Загрузка эмбеддингов пользователей\n",
    "with open('../data/emb/embeddings.json', 'r') as f:\n",
    "    user_embeddings = json.load(f)\n",
    "\n",
    "# Преобразование эмбеддингов пользователей в словарь для быстрого доступа\n",
    "user2embedding = {int(user['id']): user['embedding'] for user in user_embeddings}\n",
    "\n",
    "# Подготовка последовательностей для обучения, валидации и теста\n",
    "def prepare_sequences(data):\n",
    "    user_group = data.groupby('user_id')['item_id'].apply(list)\n",
    "    sequences = []\n",
    "    user_ids = []\n",
    "    for user_id, seq in user_group.items():\n",
    "        if len(seq) >= 2:  # Только пользователи с достаточной историей\n",
    "            sequences.append(seq)\n",
    "            user_ids.append(user_id)\n",
    "    return sequences, user_ids\n",
    "\n",
    "train_sequences, train_user_ids = prepare_sequences(train_data)\n",
    "valid_sequences, valid_user_ids = prepare_sequences(valid_data)\n",
    "test_sequences, test_user_ids = prepare_sequences(test_data)\n",
    "\n",
    "print(f'Количество пользователей в обучающем наборе: {len(train_sequences)}')\n",
    "print(f'Количество пользователей в валидационном наборе: {len(valid_sequences)}')\n",
    "print(f'Количество пользователей в тестовом наборе: {len(test_sequences)}')\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, sequences, user_ids, user_embeddings, max_len=50):\n",
    "        self.sequences = sequences\n",
    "        self.user_ids = user_ids\n",
    "        self.user_embeddings = user_embeddings\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        user_id = self.user_ids[idx]\n",
    "\n",
    "        # Получение эмбеддинга пользователя\n",
    "        embedding = self.user_embeddings.get(user_id, [0.0] * 1536)  # Обработка отсутствующих эмбеддингов\n",
    "        user_emb = torch.tensor(embedding, dtype=torch.float)\n",
    "\n",
    "        # Паддинг последовательности\n",
    "        if len(seq) < self.max_len:\n",
    "            padded_seq = [0] * (self.max_len - len(seq)) + seq\n",
    "            seq_len = len(seq)\n",
    "        else:\n",
    "            padded_seq = seq[-self.max_len:]\n",
    "            seq_len = self.max_len\n",
    "\n",
    "        return torch.tensor(padded_seq, dtype=torch.long), torch.tensor(seq_len, dtype=torch.long), user_emb\n",
    "\n",
    "# Создание датасетов и DataLoader\n",
    "train_dataset = MovieLensDataset(train_sequences, train_user_ids, user2embedding, max_len)\n",
    "valid_dataset = MovieLensDataset(valid_sequences, valid_user_ids, user2embedding, max_len)\n",
    "test_dataset = MovieLensDataset(test_sequences, test_user_ids, user2embedding, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "class LLM4SASRec(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim=50, user_embedding_dim=1536, num_heads=2, num_layers=2, dropout=0.2, max_len=50):\n",
    "        super(LLM4SASRec, self).__init__()\n",
    "        self.item_embedding = nn.Embedding(num_items + 1, embedding_dim, padding_idx=0)  # +1 для паддинга\n",
    "        self.position_embedding = nn.Embedding(max_len, embedding_dim)\n",
    "\n",
    "        # Многослойный перцептрон для сжатия эмбеддингов пользователей\n",
    "        self.user_mlp = nn.Sequential(\n",
    "            nn.Linear(user_embedding_dim, 512),  # Сжатие до промежуточной размерности\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim)  # Сжатие до итоговой размерности embedding_dim\n",
    "        )\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim,\n",
    "                                                   nhead=num_heads,\n",
    "                                                   dropout=dropout,\n",
    "                                                   activation='relu')\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(embedding_dim, num_items + 1)\n",
    "\n",
    "    def forward(self, input_seq, seq_len, user_emb):\n",
    "        # input_seq: (batch_size, max_len)\n",
    "        position_ids = torch.arange(0, input_seq.size(1), device=input_seq.device).unsqueeze(0).expand_as(input_seq)\n",
    "        item_emb = self.item_embedding(input_seq) + self.position_embedding(position_ids)\n",
    "\n",
    "        # Сжатие эмбеддингов пользователей с помощью MLP\n",
    "        user_emb_compressed = self.user_mlp(user_emb)  # (batch_size, embedding_dim)\n",
    "        user_emb_compressed = user_emb_compressed.unsqueeze(1)  # (batch_size, 1, embedding_dim)\n",
    "\n",
    "        # Добавление сжатых эмбеддингов пользователей к эмбеддингам элементов\n",
    "        item_emb = item_emb + user_emb_compressed\n",
    "\n",
    "        item_emb = self.layer_norm(item_emb)\n",
    "        item_emb = self.dropout(item_emb)\n",
    "\n",
    "        # Transformer expects input of shape (seq_len, batch_size, embedding_dim)\n",
    "        item_emb = item_emb.transpose(0, 1)\n",
    "\n",
    "        # Создание маски для паддинга\n",
    "        mask = (input_seq == 0)  # (batch_size, max_len)\n",
    "\n",
    "        # Передача через Transformer\n",
    "        output = self.transformer(item_emb, src_key_padding_mask=mask)\n",
    "        output = output.transpose(0, 1)  # (batch_size, max_len, embedding_dim)\n",
    "\n",
    "        # Предсказание последнего элемента\n",
    "        output = output[:, -1, :]  # (batch_size, embedding_dim)\n",
    "        logits = self.fc(output)    # (batch_size, num_items + 1)\n",
    "        return logits\n",
    "\n",
    "# Параметры модели\n",
    "embedding_dim = 50\n",
    "num_heads = 2\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "\n",
    "num_items = max(train_data['item_id'].max(), valid_data['item_id'].max(), test_data['item_id'].max())\n",
    "\n",
    "model = LLM4SASRec(num_items=num_items, embedding_dim=embedding_dim, user_embedding_dim=1536, num_heads=num_heads,\n",
    "                  num_layers=num_layers, dropout=dropout, max_len=max_len)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Критерий и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Игнорируем паддинг\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Функции метрик\n",
    "def precision_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / len(relevant) if relevant else 0\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(recommended):\n",
    "        if item in relevant:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(relevant), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# Функция обучения\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        sequences, lengths, user_emb = batch\n",
    "        sequences = sequences.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        user_emb = user_emb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences, lengths, user_emb)\n",
    "        targets = sequences[:, -1]  # Последний элемент последовательности\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Функция валидации (аналогично)\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, lengths, user_emb = batch\n",
    "            sequences = sequences.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            user_emb = user_emb.to(device)\n",
    "\n",
    "            outputs = model(sequences, lengths, user_emb)\n",
    "            targets = sequences[:, -1]\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Цикл обучения с валидацией\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    valid_loss = validate(model, valid_loader, criterion, device)\n",
    "    print(f'Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}')\n",
    "\n",
    "# Функция оценки\n",
    "def evaluate(model, loader, device, k=10):\n",
    "    model.eval()\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    ndcg_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, lengths, user_emb = batch\n",
    "            sequences = sequences.to(device)\n",
    "            user_emb = user_emb.to(device)\n",
    "            targets = sequences[:, -1]  # Последний элемент, который нужно предсказать\n",
    "\n",
    "            # Получение предсказаний\n",
    "            outputs = model(sequences, lengths, user_emb)  # (batch_size, num_items + 1)\n",
    "            _, top_k_items = torch.topk(outputs, k, dim=1)  # Получаем top-K предсказаний для каждого пользователя\n",
    "\n",
    "            # Цикл по батчу для расчета метрик\n",
    "            for i in range(sequences.size(0)):\n",
    "                recommended_items = top_k_items[i].cpu().numpy()\n",
    "                relevant_items = [targets[i].item()]\n",
    "\n",
    "                precision_scores.append(precision_at_k(recommended_items, relevant_items, k))\n",
    "                recall_scores.append(recall_at_k(recommended_items, relevant_items, k))\n",
    "                ndcg_scores.append(ndcg_at_k(recommended_items, relevant_items, k))\n",
    "\n",
    "    # Среднее значение метрик по всем пользователям\n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    mean_ndcg = np.mean(ndcg_scores)\n",
    "\n",
    "    return mean_precision, mean_recall, mean_ndcg\n",
    "\n",
    "# Параметр K для top-K рекомендаций\n",
    "k = 10\n",
    "\n",
    "# Оценка модели\n",
    "precision, recall, ndcg = evaluate(model, test_loader, device, k=k)\n",
    "print(f'Precision@{k}: {precision:.4f}')\n",
    "print(f'Recall@{k}: {recall:.4f}')\n",
    "print(f'NDCG@{k}: {ndcg:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SASRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (697378, 4)\n",
      "Valid size: (99582, 4)\n",
      "Test size: (203165, 4)\n",
      "Количество пользователей в обучающем наборе: 6040\n",
      "Количество пользователей в валидационном наборе: 5954\n",
      "Количество пользователей в тестовом наборе: 6040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\redpo\\Desktop\\sasrec-bert4rec-recsys23\\.venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 7.9844, Valid Loss: 7.4009\n",
      "Epoch 2/10, Train Loss: 6.9228, Valid Loss: 6.6205\n",
      "Epoch 3/10, Train Loss: 6.0998, Valid Loss: 5.8244\n",
      "Epoch 4/10, Train Loss: 5.3035, Valid Loss: 5.0009\n",
      "Epoch 5/10, Train Loss: 4.5375, Valid Loss: 4.2878\n",
      "Epoch 6/10, Train Loss: 3.8380, Valid Loss: 3.6935\n",
      "Epoch 7/10, Train Loss: 3.2466, Valid Loss: 3.2040\n",
      "Epoch 8/10, Train Loss: 2.7352, Valid Loss: 2.8522\n",
      "Epoch 9/10, Train Loss: 2.3127, Valid Loss: 2.5517\n",
      "Epoch 10/10, Train Loss: 1.9615, Valid Loss: 2.3115\n",
      "Precision@10: 0.0771\n",
      "Recall@10: 0.7709\n",
      "NDCG@10: 0.7307\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Параметры\n",
    "max_len = 50        # Максимальная длина последовательности\n",
    "batch_size = 128    # Размер батча\n",
    "\n",
    "# Файлы данных\n",
    "train_file = '../data/source/1_ml-1m_original.part1.inter'\n",
    "valid_file = '../data/source/1_ml-1m_original.part2.inter'\n",
    "test_file = '../data/source/1_ml-1m_original.part3.inter'\n",
    "\n",
    "# Загрузка данных\n",
    "train_data = pd.read_csv(train_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "valid_data = pd.read_csv(valid_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "test_data = pd.read_csv(test_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "\n",
    "print(f'Train size: {train_data.shape}')\n",
    "print(f'Valid size: {valid_data.shape}')\n",
    "print(f'Test size: {test_data.shape}')\n",
    "\n",
    "# Для отображения первых строк DataFrame (только если вы работаете в Jupyter Notebook)\n",
    "# display(train_data.head())\n",
    "\n",
    "# Подготовка последовательностей для обучения, валидации и теста\n",
    "def prepare_sequences(data):\n",
    "    user_group = data.groupby('user_id')['item_id'].apply(list)\n",
    "    sequences = []\n",
    "    user_ids = []\n",
    "    for user_id, seq in user_group.items():\n",
    "        if len(seq) >= 2:  # Только пользователи с достаточной историей\n",
    "            sequences.append(seq)\n",
    "            user_ids.append(user_id)\n",
    "    return sequences, user_ids\n",
    "\n",
    "train_sequences, train_user_ids = prepare_sequences(train_data)\n",
    "valid_sequences, valid_user_ids = prepare_sequences(valid_data)\n",
    "test_sequences, test_user_ids = prepare_sequences(test_data)\n",
    "\n",
    "print(f'Количество пользователей в обучающем наборе: {len(train_sequences)}')\n",
    "print(f'Количество пользователей в валидационном наборе: {len(valid_sequences)}')\n",
    "print(f'Количество пользователей в тестовом наборе: {len(test_sequences)}')\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, sequences, max_len=50):\n",
    "        self.sequences = sequences\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "\n",
    "        # Паддинг последовательности\n",
    "        if len(seq) < self.max_len:\n",
    "            padded_seq = [0] * (self.max_len - len(seq)) + seq\n",
    "            seq_len = len(seq)\n",
    "        else:\n",
    "            padded_seq = seq[-self.max_len:]\n",
    "            seq_len = self.max_len\n",
    "\n",
    "        return torch.tensor(padded_seq, dtype=torch.long), torch.tensor(seq_len, dtype=torch.long)\n",
    "\n",
    "# Создание датасетов и DataLoader\n",
    "train_dataset = MovieLensDataset(train_sequences, max_len)\n",
    "valid_dataset = MovieLensDataset(valid_sequences, max_len)\n",
    "test_dataset = MovieLensDataset(test_sequences, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "class SASRec(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim=50, num_heads=2, num_layers=2, dropout=0.2, max_len=50):\n",
    "        super(SASRec, self).__init__()\n",
    "        self.item_embedding = nn.Embedding(num_items + 1, embedding_dim, padding_idx=0)  # +1 для паддинга\n",
    "        self.position_embedding = nn.Embedding(max_len, embedding_dim)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim,\n",
    "                                                   nhead=num_heads,\n",
    "                                                   dropout=dropout,\n",
    "                                                   activation='relu')\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(embedding_dim, num_items + 1)\n",
    "\n",
    "    def forward(self, input_seq, seq_len):\n",
    "        # input_seq: (batch_size, max_len)\n",
    "        position_ids = torch.arange(0, input_seq.size(1), device=input_seq.device).unsqueeze(0).expand_as(input_seq)\n",
    "        item_emb = self.item_embedding(input_seq) + self.position_embedding(position_ids)\n",
    "\n",
    "        item_emb = self.layer_norm(item_emb)\n",
    "        item_emb = self.dropout(item_emb)\n",
    "\n",
    "        # Transformer ожидает ввод формы (seq_len, batch_size, embedding_dim)\n",
    "        item_emb = item_emb.transpose(0, 1)\n",
    "\n",
    "        # Создание маски для паддинга\n",
    "        mask = (input_seq == 0)  # (batch_size, max_len)\n",
    "\n",
    "        # Передача через Transformer\n",
    "        output = self.transformer(item_emb, src_key_padding_mask=mask)\n",
    "        output = output.transpose(0, 1)  # (batch_size, max_len, embedding_dim)\n",
    "\n",
    "        # Предсказание последнего элемента\n",
    "        output = output[:, -1, :]  # (batch_size, embedding_dim)\n",
    "        logits = self.fc(output)    # (batch_size, num_items + 1)\n",
    "        return logits\n",
    "\n",
    "# Параметры модели\n",
    "embedding_dim = 50\n",
    "num_heads = 2\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "\n",
    "num_items = max(train_data['item_id'].max(), valid_data['item_id'].max(), test_data['item_id'].max())\n",
    "\n",
    "model = SASRec(num_items=num_items, embedding_dim=embedding_dim, num_heads=num_heads,\n",
    "              num_layers=num_layers, dropout=dropout, max_len=max_len)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Критерий и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Игнорируем паддинг\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Функции метрик\n",
    "def precision_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / len(relevant) if relevant else 0\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(recommended):\n",
    "        if item in relevant:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(relevant), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# Функция обучения\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        sequences, lengths = batch\n",
    "        sequences = sequences.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences, lengths)\n",
    "        targets = sequences[:, -1]  # Последний элемент последовательности\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Функция валидации\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, lengths = batch\n",
    "            sequences = sequences.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            outputs = model(sequences, lengths)\n",
    "            targets = sequences[:, -1]\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Функция оценки\n",
    "def evaluate_model(model, loader, device, k=10):\n",
    "    model.eval()\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    ndcg_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, lengths = batch\n",
    "            sequences = sequences.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            targets = sequences[:, -1]  # Последний элемент, который нужно предсказать\n",
    "\n",
    "            # Получение предсказаний\n",
    "            outputs = model(sequences, lengths)  # (batch_size, num_items + 1)\n",
    "            _, top_k_items = torch.topk(outputs, k, dim=1)  # Получаем top-K предсказаний для каждого пользователя\n",
    "\n",
    "            # Цикл по батчу для расчета метрик\n",
    "            for i in range(sequences.size(0)):\n",
    "                recommended_items = top_k_items[i].cpu().numpy()\n",
    "                relevant_items = [targets[i].item()]\n",
    "\n",
    "                precision_scores.append(precision_at_k(recommended_items, relevant_items, k))\n",
    "                recall_scores.append(recall_at_k(recommended_items, relevant_items, k))\n",
    "                ndcg_scores.append(ndcg_at_k(recommended_items, relevant_items, k))\n",
    "\n",
    "    # Среднее значение метрик по всем пользователям\n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    mean_ndcg = np.mean(ndcg_scores)\n",
    "\n",
    "    return mean_precision, mean_recall, mean_ndcg\n",
    "\n",
    "# Цикл обучения с валидацией\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    valid_loss = validate(model, valid_loader, criterion, device)\n",
    "    print(f'Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}')\n",
    "\n",
    "# Параметр K для top-K рекомендаций\n",
    "k = 10\n",
    "\n",
    "# Оценка модели\n",
    "precision, recall, ndcg = evaluate_model(model, test_loader, device, k=k)\n",
    "print(f'Precision@{k}: {precision:.4f}')\n",
    "print(f'Recall@{k}: {recall:.4f}')\n",
    "print(f'NDCG@{k}: {ndcg:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (697378, 4)\n",
      "Valid size: (99582, 4)\n",
      "Test size: (203165, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>978300019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>978300103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1     3186       4  978300019\n",
       "1        1     1721       4  978300055\n",
       "2        1     1022       5  978300055\n",
       "3        1     1270       5  978300055\n",
       "4        1     2340       3  978300103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пользователей в обучающем наборе: 6040\n",
      "Количество пользователей в валидационном наборе: 5954\n",
      "Количество пользователей в тестовом наборе: 6040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\redpo\\Desktop\\sasrec-bert4rec-recsys23\\.venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 7.8055, Valid Loss: 6.9700\n",
      "Epoch 2/10, Train Loss: 6.3107, Valid Loss: 5.7959\n",
      "Epoch 3/10, Train Loss: 5.1090, Valid Loss: 4.6177\n",
      "Epoch 4/10, Train Loss: 3.9598, Valid Loss: 3.6678\n",
      "Epoch 5/10, Train Loss: 2.9946, Valid Loss: 2.9693\n",
      "Epoch 6/10, Train Loss: 2.2658, Valid Loss: 2.4313\n",
      "Epoch 7/10, Train Loss: 1.7370, Valid Loss: 2.0812\n",
      "Epoch 8/10, Train Loss: 1.3129, Valid Loss: 1.8749\n",
      "Epoch 9/10, Train Loss: 1.0104, Valid Loss: 1.7153\n",
      "Epoch 10/10, Train Loss: 0.7802, Valid Loss: 1.5260\n",
      "Precision@10: 0.0846\n",
      "Recall@10: 0.8455\n",
      "NDCG@10: 0.8368\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader  # Добавленные импорты\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Параметры\n",
    "max_len = 50        # Определение max_len\n",
    "batch_size = 128    # Определение batch_size\n",
    "\n",
    "# Файлы данных\n",
    "train_file = '../data/source/1_ml-1m_original.part1.inter'\n",
    "valid_file = '../data/source/1_ml-1m_original.part2.inter'\n",
    "test_file = '../data/source/1_ml-1m_original.part3.inter'\n",
    "\n",
    "# Загрузка данных\n",
    "train_data = pd.read_csv(train_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "valid_data = pd.read_csv(valid_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "test_data = pd.read_csv(test_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "\n",
    "print(f'Train size: {train_data.shape}')\n",
    "print(f'Valid size: {valid_data.shape}')\n",
    "print(f'Test size: {test_data.shape}')\n",
    "\n",
    "display(train_data.head())\n",
    "\n",
    "# Загрузка эмбеддингов пользователей\n",
    "with open('../data/emb/embeddings.json', 'r') as f:\n",
    "    user_embeddings = json.load(f)\n",
    "\n",
    "# Преобразование эмбеддингов пользователей в словарь для быстрого доступа\n",
    "user2embedding = {int(user['id']): user['embedding'] for user in user_embeddings}\n",
    "\n",
    "# Подготовка последовательностей для обучения, валидации и теста\n",
    "def prepare_sequences(data):\n",
    "    user_group = data.groupby('user_id')['item_id'].apply(list)\n",
    "    sequences = []\n",
    "    user_ids = []\n",
    "    for user_id, seq in user_group.items():\n",
    "        if len(seq) >= 2:  # Только пользователи с достаточной историей\n",
    "            sequences.append(seq)\n",
    "            user_ids.append(user_id)\n",
    "    return sequences, user_ids\n",
    "\n",
    "train_sequences, train_user_ids = prepare_sequences(train_data)\n",
    "valid_sequences, valid_user_ids = prepare_sequences(valid_data)\n",
    "test_sequences, test_user_ids = prepare_sequences(test_data)\n",
    "\n",
    "print(f'Количество пользователей в обучающем наборе: {len(train_sequences)}')\n",
    "print(f'Количество пользователей в валидационном наборе: {len(valid_sequences)}')\n",
    "print(f'Количество пользователей в тестовом наборе: {len(test_sequences)}')\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, sequences, user_ids, user_embeddings, max_len=50):\n",
    "        self.sequences = sequences\n",
    "        self.user_ids = user_ids\n",
    "        self.user_embeddings = user_embeddings\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        user_id = self.user_ids[idx]\n",
    "\n",
    "        # Получение эмбеддинга пользователя\n",
    "        embedding = self.user_embeddings.get(user_id, [0.0] * 1536)  # Обработка отсутствующих эмбеддингов\n",
    "        user_emb = torch.tensor(embedding, dtype=torch.float)\n",
    "\n",
    "        # Паддинг последовательности\n",
    "        if len(seq) < self.max_len:\n",
    "            padded_seq = [0] * (self.max_len - len(seq)) + seq\n",
    "            seq_len = len(seq)\n",
    "        else:\n",
    "            padded_seq = seq[-self.max_len:]\n",
    "            seq_len = self.max_len\n",
    "\n",
    "        return torch.tensor(padded_seq, dtype=torch.long), torch.tensor(seq_len, dtype=torch.long), user_emb\n",
    "\n",
    "# Создание датасетов и DataLoader\n",
    "train_dataset = MovieLensDataset(train_sequences, train_user_ids, user2embedding, max_len)\n",
    "valid_dataset = MovieLensDataset(valid_sequences, valid_user_ids, user2embedding, max_len)\n",
    "test_dataset = MovieLensDataset(test_sequences, test_user_ids, user2embedding, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "class LLM4SASRec(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim=50, user_embedding_dim=1536, num_heads=2, num_layers=2, dropout=0.2, max_len=50):\n",
    "        super(LLM4SASRec, self).__init__()\n",
    "        self.item_embedding = nn.Embedding(num_items + 1, embedding_dim, padding_idx=0)  # +1 for padding\n",
    "        self.position_embedding = nn.Embedding(max_len, embedding_dim)\n",
    "        \n",
    "        # Compress user embedding\n",
    "        self.user_mlp = nn.Sequential(\n",
    "            nn.Linear(user_embedding_dim, embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Adjust embedding dimension for concatenation\n",
    "        self.combined_embedding_dim = embedding_dim * 2  # Example: Concatenating user and item embeddings\n",
    "        \n",
    "        # Transformer expects this new embedding size\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.combined_embedding_dim,\n",
    "                                                   nhead=num_heads,\n",
    "                                                   dropout=dropout,\n",
    "                                                   activation='relu')\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(self.combined_embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(self.combined_embedding_dim, num_items + 1)\n",
    "    \n",
    "    def forward(self, input_seq, seq_len, user_emb):\n",
    "        # Embed items and positions\n",
    "        item_emb = self.item_embedding(input_seq) + self.position_embedding(torch.arange(0, input_seq.size(1), device=input_seq.device).unsqueeze(0).expand_as(input_seq))\n",
    "        \n",
    "        # Compress user embeddings\n",
    "        user_emb_compressed = self.user_mlp(user_emb)  # (batch_size, embedding_dim)\n",
    "        user_emb_expanded = user_emb_compressed.unsqueeze(1).repeat(1, input_seq.size(1), 1)  # (batch_size, max_len, embedding_dim)\n",
    "        \n",
    "        # Concatenate item and user embeddings\n",
    "        combined_emb = torch.cat([item_emb, user_emb_expanded], dim=-1)  # (batch_size, max_len, combined_embedding_dim)\n",
    "        \n",
    "        combined_emb = self.layer_norm(combined_emb)\n",
    "        combined_emb = self.dropout(combined_emb)\n",
    "        \n",
    "        # Transformer expects (seq_len, batch_size, embedding_dim)\n",
    "        combined_emb = combined_emb.transpose(0, 1)\n",
    "        \n",
    "        # Create padding mask\n",
    "        mask = (input_seq == 0)  # (batch_size, max_len)\n",
    "        \n",
    "        # Pass through Transformer\n",
    "        output = self.transformer(combined_emb, src_key_padding_mask=mask)\n",
    "        output = output.transpose(0, 1)  # (batch_size, max_len, combined_embedding_dim)\n",
    "        \n",
    "        # Use the last item in the sequence\n",
    "        output = output[:, -1, :]  # (batch_size, combined_embedding_dim)\n",
    "        logits = self.fc(output)    # (batch_size, num_items + 1)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Параметры модели\n",
    "embedding_dim = 50\n",
    "num_heads = 2\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "\n",
    "num_items = max(train_data['item_id'].max(), valid_data['item_id'].max(), test_data['item_id'].max())\n",
    "\n",
    "model = LLM4SASRec(num_items=num_items, embedding_dim=embedding_dim, user_embedding_dim=1536, num_heads=num_heads,\n",
    "                  num_layers=num_layers, dropout=dropout, max_len=max_len)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Критерий и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Игнорируем паддинг\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Функции метрик\n",
    "def precision_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / len(relevant) if relevant else 0\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(recommended):\n",
    "        if item in relevant:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(relevant), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# Функция обучения\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        sequences, lengths, user_emb = batch\n",
    "        sequences = sequences.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        user_emb = user_emb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences, lengths, user_emb)\n",
    "        targets = sequences[:, -1]  # Последний элемент последовательности\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Функция валидации (аналогично)\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, lengths, user_emb = batch\n",
    "            sequences = sequences.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            user_emb = user_emb.to(device)\n",
    "\n",
    "            outputs = model(sequences, lengths, user_emb)\n",
    "            targets = sequences[:, -1]\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Цикл обучения с валидацией\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    valid_loss = validate(model, valid_loader, criterion, device)\n",
    "    print(f'Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}')\n",
    "\n",
    "# Функция оценки\n",
    "def evaluate(model, loader, device, k=10):\n",
    "    model.eval()\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    ndcg_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, lengths, user_emb = batch\n",
    "            sequences = sequences.to(device)\n",
    "            user_emb = user_emb.to(device)\n",
    "            targets = sequences[:, -1]  # Последний элемент, который нужно предсказать\n",
    "\n",
    "            # Получение предсказаний\n",
    "            outputs = model(sequences, lengths, user_emb)  # (batch_size, num_items + 1)\n",
    "            _, top_k_items = torch.topk(outputs, k, dim=1)  # Получаем top-K предсказаний для каждого пользователя\n",
    "\n",
    "            # Цикл по батчу для расчета метрик\n",
    "            for i in range(sequences.size(0)):\n",
    "                recommended_items = top_k_items[i].cpu().numpy()\n",
    "                relevant_items = [targets[i].item()]\n",
    "\n",
    "                precision_scores.append(precision_at_k(recommended_items, relevant_items, k))\n",
    "                recall_scores.append(recall_at_k(recommended_items, relevant_items, k))\n",
    "                ndcg_scores.append(ndcg_at_k(recommended_items, relevant_items, k))\n",
    "\n",
    "    # Среднее значение метрик по всем пользователям\n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    mean_ndcg = np.mean(ndcg_scores)\n",
    "\n",
    "    return mean_precision, mean_recall, mean_ndcg\n",
    "\n",
    "# Параметр K для top-K рекомендаций\n",
    "k = 10\n",
    "\n",
    "# Оценка модели\n",
    "precision, recall, ndcg = evaluate(model, test_loader, device, k=k)\n",
    "print(f'Precision@{k}: {precision:.4f}')\n",
    "print(f'Recall@{k}: {recall:.4f}')\n",
    "print(f'NDCG@{k}: {ndcg:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CrossLayer(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CrossLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.weight = nn.Parameter(torch.randn(input_dim, 1))\n",
    "        self.bias = nn.Parameter(torch.randn(input_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, input_dim)\n",
    "        x_0 = x\n",
    "        x_l = torch.matmul(x, self.weight) + self.bias  # (batch_size, 1)\n",
    "        x_l = x_0 * x_l  # Broadcasting to (batch_size, input_dim)\n",
    "        return x_l\n",
    "\n",
    "class DCNv2(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers=2):\n",
    "        super(DCNv2, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.cross_layers = nn.ModuleList([CrossLayer(input_dim) for _ in range(num_layers)])\n",
    "        self.output_layer = nn.Linear(input_dim * (num_layers + 1), input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, input_dim)\n",
    "        x_0 = x\n",
    "        x_l = x\n",
    "        outputs = [x_0]\n",
    "        for cross_layer in self.cross_layers:\n",
    "            x_l = cross_layer(x_l)\n",
    "            outputs.append(x_l)\n",
    "        concatenated = torch.cat(outputs, dim=1)  # (batch_size, input_dim * (num_layers +1))\n",
    "        output = self.output_layer(concatenated)   # (batch_size, input_dim)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (697378, 4)\n",
      "Valid size: (99582, 4)\n",
      "Test size: (203165, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>978300019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>978300103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1     3186       4  978300019\n",
       "1        1     1721       4  978300055\n",
       "2        1     1022       5  978300055\n",
       "3        1     1270       5  978300055\n",
       "4        1     2340       3  978300103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пользователей в обучающем наборе: 6040\n",
      "Количество пользователей в валидационном наборе: 5954\n",
      "Количество пользователей в тестовом наборе: 6040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\redpo\\Desktop\\sasrec-bert4rec-recsys23\\.venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 7.7511, Valid Loss: 6.9217\n",
      "Epoch 2/10, Train Loss: 6.2159, Valid Loss: 5.7334\n",
      "Epoch 3/10, Train Loss: 4.9703, Valid Loss: 4.4953\n",
      "Epoch 4/10, Train Loss: 3.8098, Valid Loss: 3.5088\n",
      "Epoch 5/10, Train Loss: 2.8761, Valid Loss: 2.8212\n",
      "Epoch 6/10, Train Loss: 2.1693, Valid Loss: 2.3564\n",
      "Epoch 7/10, Train Loss: 1.6431, Valid Loss: 2.0391\n",
      "Epoch 8/10, Train Loss: 1.2383, Valid Loss: 1.8013\n",
      "Epoch 9/10, Train Loss: 0.9685, Valid Loss: 1.6643\n",
      "Epoch 10/10, Train Loss: 0.7351, Valid Loss: 1.5650\n",
      "Precision@10: 0.0846\n",
      "Recall@10: 0.8455\n",
      "NDCG@10: 0.8404\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Параметры\n",
    "max_len = 50\n",
    "batch_size = 128\n",
    "\n",
    "# Файлы данных\n",
    "train_file = '../data/source/1_ml-1m_original.part1.inter'\n",
    "valid_file = '../data/source/1_ml-1m_original.part2.inter'\n",
    "test_file = '../data/source/1_ml-1m_original.part3.inter'\n",
    "\n",
    "# Загрузка данных\n",
    "train_data = pd.read_csv(train_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "valid_data = pd.read_csv(valid_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "test_data = pd.read_csv(test_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "\n",
    "print(f'Train size: {train_data.shape}')\n",
    "print(f'Valid size: {valid_data.shape}')\n",
    "print(f'Test size: {test_data.shape}')\n",
    "\n",
    "display(train_data.head())\n",
    "\n",
    "# Загрузка эмбеддингов пользователей\n",
    "with open('../data/emb/embeddings.json', 'r') as f:\n",
    "    user_embeddings = json.load(f)\n",
    "\n",
    "# Преобразование эмбеддингов пользователей в словарь для быстрого доступа\n",
    "user2embedding = {int(user['id']): user['embedding'] for user in user_embeddings}\n",
    "\n",
    "# Подготовка последовательностей для обучения, валидации и теста\n",
    "def prepare_sequences(data):\n",
    "    user_group = data.groupby('user_id')['item_id'].apply(list)\n",
    "    sequences = []\n",
    "    user_ids = []\n",
    "    for user_id, seq in user_group.items():\n",
    "        if len(seq) >= 2:  # Только пользователи с достаточной историей\n",
    "            sequences.append(seq)\n",
    "            user_ids.append(user_id)\n",
    "    return sequences, user_ids\n",
    "\n",
    "train_sequences, train_user_ids = prepare_sequences(train_data)\n",
    "valid_sequences, valid_user_ids = prepare_sequences(valid_data)\n",
    "test_sequences, test_user_ids = prepare_sequences(test_data)\n",
    "\n",
    "print(f'Количество пользователей в обучающем наборе: {len(train_sequences)}')\n",
    "print(f'Количество пользователей в валидационном наборе: {len(valid_sequences)}')\n",
    "print(f'Количество пользователей в тестовом наборе: {len(test_sequences)}')\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, sequences, user_ids, user_embeddings, max_len=50):\n",
    "        self.sequences = sequences\n",
    "        self.user_ids = user_ids\n",
    "        self.user_embeddings = user_embeddings\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        user_id = self.user_ids[idx]\n",
    "\n",
    "        # Получение эмбеддинга пользователя\n",
    "        embedding = self.user_embeddings.get(user_id, [0.0] * 1536)  # Обработка отсутствующих эмбеддингов\n",
    "        user_emb = torch.tensor(embedding, dtype=torch.float)\n",
    "\n",
    "        # Паддинг последовательности\n",
    "        if len(seq) < self.max_len:\n",
    "            padded_seq = [0] * (self.max_len - len(seq)) + seq\n",
    "            seq_len = len(seq)\n",
    "        else:\n",
    "            padded_seq = seq[-self.max_len:]\n",
    "            seq_len = self.max_len\n",
    "\n",
    "        return torch.tensor(padded_seq, dtype=torch.long), torch.tensor(seq_len, dtype=torch.long), user_emb\n",
    "\n",
    "# Создание датасетов и DataLoader\n",
    "train_dataset = MovieLensDataset(train_sequences, train_user_ids, user2embedding, max_len)\n",
    "valid_dataset = MovieLensDataset(valid_sequences, valid_user_ids, user2embedding, max_len)\n",
    "test_dataset = MovieLensDataset(test_sequences, test_user_ids, user2embedding, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Реализация DCNv2\n",
    "class CrossLayer(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CrossLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.weight = nn.Parameter(torch.randn(input_dim, 1))\n",
    "        self.bias = nn.Parameter(torch.randn(input_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, input_dim)\n",
    "        x_0 = x\n",
    "        x_l = torch.matmul(x, self.weight) + self.bias  # (batch_size, 1)\n",
    "        x_l = x_0 * x_l  # Broadcasting to (batch_size, input_dim)\n",
    "        return x_l\n",
    "\n",
    "class DCNv2(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers=2):\n",
    "        super(DCNv2, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.cross_layers = nn.ModuleList([CrossLayer(input_dim) for _ in range(num_layers)])\n",
    "        self.output_layer = nn.Linear(input_dim * (num_layers + 1), input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, input_dim)\n",
    "        x_0 = x\n",
    "        x_l = x\n",
    "        outputs = [x_0]\n",
    "        for cross_layer in self.cross_layers:\n",
    "            x_l = cross_layer(x_l)\n",
    "            outputs.append(x_l)\n",
    "        concatenated = torch.cat(outputs, dim=1)  # (batch_size, input_dim * (num_layers +1))\n",
    "        output = self.output_layer(concatenated)   # (batch_size, input_dim)\n",
    "        return output\n",
    "\n",
    "# Модифицированный класс LLM4SASRec с DCNv2\n",
    "class LLM4SASRecDCNv2(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim=50, user_embedding_dim=1536, num_heads=2, num_layers=2, dropout=0.2, max_len=50, cross_num_layers=2):\n",
    "        super(LLM4SASRecDCNv2, self).__init__()\n",
    "        self.item_embedding = nn.Embedding(num_items + 1, embedding_dim, padding_idx=0)\n",
    "        self.position_embedding = nn.Embedding(max_len, embedding_dim)\n",
    "        \n",
    "        # Замена MLP на DCNv2 для обработки эмбеддингов пользователей\n",
    "        self.user_dcnv2 = DCNv2(user_embedding_dim, num_layers=cross_num_layers)\n",
    "        self.user_compress = nn.Linear(user_embedding_dim, embedding_dim)  # Преобразование размера после DCNv2\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Размер объединенного эмбеддинга\n",
    "        combined_dim = embedding_dim * 2\n",
    "        \n",
    "        # Слои трансформера с обновленной размерностью\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=combined_dim,\n",
    "                                                   nhead=num_heads,\n",
    "                                                   dropout=dropout,\n",
    "                                                   activation='relu')\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(combined_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(combined_dim, num_items + 1)\n",
    "    \n",
    "    def forward(self, input_seq, seq_len, user_emb):\n",
    "        # Встраивание элементов и позиций\n",
    "        item_emb = self.item_embedding(input_seq) + self.position_embedding(\n",
    "            torch.arange(0, input_seq.size(1), device=input_seq.device).unsqueeze(0).expand_as(input_seq)\n",
    "        )\n",
    "        \n",
    "        # Обработка эмбеддингов пользователей через DCNv2\n",
    "        user_emb_processed = self.user_dcnv2(user_emb)  # (batch_size, user_embedding_dim)\n",
    "        user_emb_compressed = self.user_compress(user_emb_processed)  # (batch_size, embedding_dim)\n",
    "        user_emb_compressed = self.relu(user_emb_compressed)  # Нелинейность\n",
    "        \n",
    "        user_emb_expanded = user_emb_compressed.unsqueeze(1).repeat(1, input_seq.size(1), 1)  # (batch_size, max_len, embedding_dim)\n",
    "        \n",
    "        # Конкатенация эмбеддингов элементов и пользователей\n",
    "        combined_emb = torch.cat([item_emb, user_emb_expanded], dim=-1)  # (batch_size, max_len, combined_dim)\n",
    "        \n",
    "        combined_emb = self.layer_norm(combined_emb)\n",
    "        combined_emb = self.dropout(combined_emb)\n",
    "        \n",
    "        # Трансформер ожидает вход размерности (seq_len, batch_size, embedding_dim)\n",
    "        combined_emb = combined_emb.transpose(0, 1)\n",
    "        \n",
    "        # Создание маски для паддинга\n",
    "        mask = (input_seq == 0)  # (batch_size, max_len)\n",
    "        \n",
    "        # Пропуск через трансформер\n",
    "        output = self.transformer(combined_emb, src_key_padding_mask=mask)\n",
    "        output = output.transpose(0, 1)  # (batch_size, max_len, combined_dim)\n",
    "        \n",
    "        # Использование последнего элемента последовательности\n",
    "        output = output[:, -1, :]  # (batch_size, combined_dim)\n",
    "        logits = self.fc(output)    # (batch_size, num_items + 1)\n",
    "        return logits\n",
    "\n",
    "# Параметры модели\n",
    "embedding_dim = 50\n",
    "num_heads = 2\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "cross_num_layers = 2  # Количество слоев в DCNv2\n",
    "\n",
    "num_items = max(train_data['item_id'].max(), valid_data['item_id'].max(), test_data['item_id'].max())\n",
    "\n",
    "model = LLM4SASRecDCNv2(\n",
    "    num_items=num_items,\n",
    "    embedding_dim=embedding_dim,\n",
    "    user_embedding_dim=1536,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    max_len=max_len,\n",
    "    cross_num_layers=cross_num_layers\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Критерий и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Игнорируем паддинг\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Функции метрик (оставляем без изменений)\n",
    "def precision_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / len(relevant) if relevant else 0\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(recommended):\n",
    "        if item in relevant:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(relevant), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# Функция обучения\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        sequences, lengths, user_emb = batch\n",
    "        sequences = sequences.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        user_emb = user_emb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences, lengths, user_emb)\n",
    "        targets = sequences[:, -1]  # Последний элемент последовательности\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Функция валидации (аналогично)\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, lengths, user_emb = batch\n",
    "            sequences = sequences.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            user_emb = user_emb.to(device)\n",
    "\n",
    "            outputs = model(sequences, lengths, user_emb)\n",
    "            targets = sequences[:, -1]\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Цикл обучения с валидацией\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    valid_loss = validate(model, valid_loader, criterion, device)\n",
    "    print(f'Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}')\n",
    "\n",
    "# Функция оценки\n",
    "def evaluate(model, loader, device, k=10):\n",
    "    model.eval()\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    ndcg_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, lengths, user_emb = batch\n",
    "            sequences = sequences.to(device)\n",
    "            user_emb = user_emb.to(device)\n",
    "            targets = sequences[:, -1]  # Последний элемент, который нужно предсказать\n",
    "\n",
    "            # Получение предсказаний\n",
    "            outputs = model(sequences, lengths, user_emb)  # (batch_size, num_items + 1)\n",
    "            _, top_k_items = torch.topk(outputs, k, dim=1)  # Получаем top-K предсказаний для каждого пользователя\n",
    "\n",
    "            # Цикл по батчу для расчета метрик\n",
    "            for i in range(sequences.size(0)):\n",
    "                recommended_items = top_k_items[i].cpu().numpy()\n",
    "                relevant_items = [targets[i].item()]\n",
    "\n",
    "                precision_scores.append(precision_at_k(recommended_items, relevant_items, k))\n",
    "                recall_scores.append(recall_at_k(recommended_items, relevant_items, k))\n",
    "                ndcg_scores.append(ndcg_at_k(recommended_items, relevant_items, k))\n",
    "\n",
    "    # Среднее значение метрик по всем пользователям\n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    mean_ndcg = np.mean(ndcg_scores)\n",
    "\n",
    "    return mean_precision, mean_recall, mean_ndcg\n",
    "\n",
    "# Параметр K для top-K рекомендаций\n",
    "k = 10\n",
    "\n",
    "# Оценка модели\n",
    "precision, recall, ndcg = evaluate(model, test_loader, device, k=k)\n",
    "print(f'Precision@{k}: {precision:.4f}')\n",
    "print(f'Recall@{k}: {recall:.4f}')\n",
    "print(f'NDCG@{k}: {ndcg:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (697378, 4)\n",
      "Valid size: (99582, 4)\n",
      "Test size: (203165, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>978300019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>978300103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1     3186       4  978300019\n",
       "1        1     1721       4  978300055\n",
       "2        1     1022       5  978300055\n",
       "3        1     1270       5  978300055\n",
       "4        1     2340       3  978300103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пользователей в обучающем наборе: 6040\n",
      "Количество пользователей в валидационном наборе: 5954\n",
      "Количество пользователей в тестовом наборе: 6040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\redpo\\Desktop\\sasrec-bert4rec-recsys23\\.venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 7.9422, Valid Loss: 7.6329\n",
      "Epoch 2/10, Train Loss: 7.1730, Valid Loss: 7.1856\n",
      "Epoch 3/10, Train Loss: 6.4390, Valid Loss: 6.1652\n",
      "Epoch 4/10, Train Loss: 5.5145, Valid Loss: 5.3553\n",
      "Epoch 5/10, Train Loss: 4.6197, Valid Loss: 4.5000\n",
      "Epoch 6/10, Train Loss: 3.7164, Valid Loss: 3.7588\n",
      "Epoch 7/10, Train Loss: 2.9334, Valid Loss: 3.1174\n",
      "Epoch 8/10, Train Loss: 2.2881, Valid Loss: 2.6364\n",
      "Epoch 9/10, Train Loss: 1.7908, Valid Loss: 2.2751\n",
      "Epoch 10/10, Train Loss: 1.3949, Valid Loss: 1.9985\n",
      "Precision@10: 0.0846\n",
      "Recall@10: 0.8455\n",
      "NDCG@10: 0.8368\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Параметры\n",
    "max_len = 50\n",
    "batch_size = 128\n",
    "\n",
    "# Файлы данных\n",
    "train_file = '../data/source/1_ml-1m_original.part1.inter'\n",
    "valid_file = '../data/source/1_ml-1m_original.part2.inter'\n",
    "test_file = '../data/source/1_ml-1m_original.part3.inter'\n",
    "\n",
    "# Загрузка данных\n",
    "train_data = pd.read_csv(train_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "valid_data = pd.read_csv(valid_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "test_data = pd.read_csv(test_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "\n",
    "print(f'Train size: {train_data.shape}')\n",
    "print(f'Valid size: {valid_data.shape}')\n",
    "print(f'Test size: {test_data.shape}')\n",
    "\n",
    "display(train_data.head())\n",
    "\n",
    "# Загрузка эмбеддингов пользователей\n",
    "with open('../data/emb/embeddings.json', 'r') as f:\n",
    "    user_embeddings = json.load(f)\n",
    "\n",
    "# Преобразование эмбеддингов пользователей в словарь для быстрого доступа\n",
    "user2embedding = {int(user['id']): user['embedding'] for user in user_embeddings}\n",
    "\n",
    "# Подготовка последовательностей для обучения, валидации и теста\n",
    "def prepare_sequences(data):\n",
    "    user_group = data.groupby('user_id')['item_id'].apply(list)\n",
    "    sequences = []\n",
    "    user_ids = []\n",
    "    for user_id, seq in user_group.items():\n",
    "        if len(seq) >= 2:  # Только пользователи с достаточной историей\n",
    "            sequences.append(seq)\n",
    "            user_ids.append(user_id)\n",
    "    return sequences, user_ids\n",
    "\n",
    "train_sequences, train_user_ids = prepare_sequences(train_data)\n",
    "valid_sequences, valid_user_ids = prepare_sequences(valid_data)\n",
    "test_sequences, test_user_ids = prepare_sequences(test_data)\n",
    "\n",
    "print(f'Количество пользователей в обучающем наборе: {len(train_sequences)}')\n",
    "print(f'Количество пользователей в валидационном наборе: {len(valid_sequences)}')\n",
    "print(f'Количество пользователей в тестовом наборе: {len(test_sequences)}')\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, sequences, user_ids, user_embeddings, max_len=50):\n",
    "        self.sequences = sequences\n",
    "        self.user_ids = user_ids\n",
    "        self.user_embeddings = user_embeddings\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        user_id = self.user_ids[idx]\n",
    "\n",
    "        # Получение эмбеддинга пользователя\n",
    "        embedding = self.user_embeddings.get(user_id, [0.0] * 1536)  # Обработка отсутствующих эмбеддингов\n",
    "        user_emb = torch.tensor(embedding, dtype=torch.float)\n",
    "\n",
    "        # Паддинг последовательности\n",
    "        if len(seq) < self.max_len:\n",
    "            padded_seq = [0] * (self.max_len - len(seq)) + seq\n",
    "            seq_len = len(seq)\n",
    "        else:\n",
    "            padded_seq = seq[-self.max_len:]\n",
    "            seq_len = self.max_len\n",
    "\n",
    "        return torch.tensor(padded_seq, dtype=torch.long), torch.tensor(seq_len, dtype=torch.long), user_emb\n",
    "\n",
    "# Создание датасетов и DataLoader\n",
    "train_dataset = MovieLensDataset(train_sequences, train_user_ids, user2embedding, max_len)\n",
    "valid_dataset = MovieLensDataset(valid_sequences, valid_user_ids, user2embedding, max_len)\n",
    "test_dataset = MovieLensDataset(test_sequences, test_user_ids, user2embedding, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Реализация класса LLM4SASRecWithAttention\n",
    "class LLM4SASRecWithAttention(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim=50, user_embedding_dim=1536, num_heads=2, num_layers=2, dropout=0.2, max_len=50):\n",
    "        super(LLM4SASRecWithAttention, self).__init__()\n",
    "        self.item_embedding = nn.Embedding(num_items + 1, embedding_dim, padding_idx=0)\n",
    "        self.position_embedding = nn.Embedding(max_len, embedding_dim)\n",
    "        \n",
    "        # Сокращение размерности эмбеддингов пользователей\n",
    "        self.user_mlp = nn.Sequential(\n",
    "            nn.Linear(user_embedding_dim, embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim,\n",
    "                                                   nhead=num_heads,\n",
    "                                                   dropout=dropout,\n",
    "                                                   activation='relu')\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(embedding_dim, num_items + 1)\n",
    "    \n",
    "    def forward(self, input_seq, seq_len, user_emb):\n",
    "        # Встраивание элементов и позиций\n",
    "        item_emb = self.item_embedding(input_seq) + self.position_embedding(\n",
    "            torch.arange(0, input_seq.size(1), device=input_seq.device).unsqueeze(0).expand_as(input_seq)\n",
    "        )\n",
    "        \n",
    "        # Сокращение эмбеддингов пользователей\n",
    "        user_emb_compressed = self.user_mlp(user_emb)  # (batch_size, embedding_dim)\n",
    "        \n",
    "        # Интеграция эмбеддингов пользователей через внимание\n",
    "        # Для простоты добавим эмбеддинг пользователя в начало последовательности\n",
    "        user_emb_expanded = user_emb_compressed.unsqueeze(1)  # (batch_size, 1, embedding_dim)\n",
    "        combined_emb = torch.cat([user_emb_expanded, item_emb], dim=1)  # (batch_size, max_len + 1, embedding_dim)\n",
    "        \n",
    "        combined_emb = self.layer_norm(combined_emb)\n",
    "        combined_emb = self.dropout(combined_emb)\n",
    "        \n",
    "        # Трансформер ожидает вход размерности (seq_len, batch_size, embedding_dim)\n",
    "        combined_emb = combined_emb.transpose(0, 1)\n",
    "        \n",
    "        # Создание маски для паддинга (игнорируем пользовательский токен)\n",
    "        mask = torch.cat([\n",
    "            torch.zeros((input_seq.size(0), 1), dtype=torch.bool, device=input_seq.device),\n",
    "            (input_seq == 0)\n",
    "        ], dim=1)  # (batch_size, max_len + 1)\n",
    "        \n",
    "        # Пропуск через трансформер\n",
    "        output = self.transformer(combined_emb, src_key_padding_mask=mask)\n",
    "        output = output.transpose(0, 1)  # (batch_size, max_len + 1, embedding_dim)\n",
    "        \n",
    "        # Использование последнего элемента последовательности (исключая пользовательский токен)\n",
    "        output = output[:, -1, :]  # (batch_size, embedding_dim)\n",
    "        logits = self.fc(output)    # (batch_size, num_items + 1)\n",
    "        return logits\n",
    "\n",
    "# Параметры модели\n",
    "embedding_dim = 50\n",
    "num_heads = 2\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "\n",
    "num_items = max(train_data['item_id'].max(), valid_data['item_id'].max(), test_data['item_id'].max())\n",
    "\n",
    "# Инициализация модели\n",
    "model = LLM4SASRecWithAttention(\n",
    "    num_items=num_items,\n",
    "    embedding_dim=embedding_dim,\n",
    "    user_embedding_dim=1536,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    max_len=max_len\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Исправленная функция инициализации весов\n",
    "def init_weights(m):\n",
    "    if isinstance(m, (nn.Linear, nn.Embedding)):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# Применение функции инициализации весов\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Критерий и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Игнорируем паддинг\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # Добавлен weight_decay\n",
    "\n",
    "# Функции метрик\n",
    "def precision_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / len(relevant) if relevant else 0\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(recommended):\n",
    "        if item in relevant:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(relevant), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# Функция обучения\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        sequences, lengths, user_emb = batch\n",
    "        sequences = sequences.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        user_emb = user_emb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences, lengths, user_emb)\n",
    "        targets = sequences[:, -1]  # Последний элемент последовательности\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Функция валидации\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, lengths, user_emb = batch\n",
    "            sequences = sequences.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            user_emb = user_emb.to(device)\n",
    "\n",
    "            outputs = model(sequences, lengths, user_emb)\n",
    "            targets = sequences[:, -1]\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Цикл обучения с валидацией\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    valid_loss = validate(model, valid_loader, criterion, device)\n",
    "    print(f'Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}')\n",
    "\n",
    "# Функция оценки\n",
    "def evaluate(model, loader, device, k=10):\n",
    "    model.eval()\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    ndcg_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, lengths, user_emb = batch\n",
    "            sequences = sequences.to(device)\n",
    "            user_emb = user_emb.to(device)\n",
    "            targets = sequences[:, -1]  # Последний элемент, который нужно предсказать\n",
    "\n",
    "            # Получение предсказаний\n",
    "            outputs = model(sequences, lengths, user_emb)  # (batch_size, num_items + 1)\n",
    "            _, top_k_items = torch.topk(outputs, k, dim=1)  # Получаем top-K предсказаний для каждого пользователя\n",
    "\n",
    "            # Цикл по батчу для расчета метрик\n",
    "            for i in range(sequences.size(0)):\n",
    "                recommended_items = top_k_items[i].cpu().numpy()\n",
    "                relevant_items = [targets[i].item()]\n",
    "\n",
    "                precision_scores.append(precision_at_k(recommended_items, relevant_items, k))\n",
    "                recall_scores.append(recall_at_k(recommended_items, relevant_items, k))\n",
    "                ndcg_scores.append(ndcg_at_k(recommended_items, relevant_items, k))\n",
    "\n",
    "    # Среднее значение метрик по всем пользователям\n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    mean_ndcg = np.mean(ndcg_scores)\n",
    "\n",
    "    return mean_precision, mean_recall, mean_ndcg\n",
    "\n",
    "# Параметр K для top-K рекомендаций\n",
    "k = 10\n",
    "\n",
    "# Оценка модели\n",
    "precision, recall, ndcg = evaluate(model, test_loader, device, k=k)\n",
    "print(f'Precision@{k}: {precision:.4f}')\n",
    "print(f'Recall@{k}: {recall:.4f}')\n",
    "print(f'NDCG@{k}: {ndcg:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (697378, 4)\n",
      "Valid size: (99582, 4)\n",
      "Test size: (203165, 4)\n",
      "Количество пользователей в обучающем наборе: 6040\n",
      "Количество пользователей в валидационном наборе: 5954\n",
      "Количество пользователей в тестовом наборе: 6040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\redpo\\Desktop\\sasrec-bert4rec-recsys23\\.venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.3668, Valid Loss: 0.1515\n",
      "Epoch 2/10, Train Loss: 0.1021, Valid Loss: 0.0736\n",
      "Epoch 3/10, Train Loss: 0.0640, Valid Loss: 0.0586\n",
      "Epoch 4/10, Train Loss: 0.0543, Valid Loss: 0.0536\n",
      "Epoch 5/10, Train Loss: 0.0504, Valid Loss: 0.0515\n",
      "Epoch 6/10, Train Loss: 0.0485, Valid Loss: 0.0503\n",
      "Epoch 7/10, Train Loss: 0.0473, Valid Loss: 0.0497\n",
      "Epoch 8/10, Train Loss: 0.0465, Valid Loss: 0.0489\n",
      "Epoch 9/10, Train Loss: 0.0453, Valid Loss: 0.0472\n",
      "Epoch 10/10, Train Loss: 0.0431, Valid Loss: 0.0448\n",
      "Precision@10: 0.0157\n",
      "Recall@10: 0.1573\n",
      "NDCG@10: 0.0712\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "# Параметры\n",
    "max_len = 50\n",
    "batch_size = 128\n",
    "num_negatives = 100  # Количество негативных примеров\n",
    "\n",
    "# Файлы данных\n",
    "train_file = '../data/source/1_ml-1m_original.part1.inter'\n",
    "valid_file = '../data/source/1_ml-1m_original.part2.inter'\n",
    "test_file = '../data/source/1_ml-1m_original.part3.inter'\n",
    "\n",
    "# Загрузка данных\n",
    "train_data = pd.read_csv(train_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "valid_data = pd.read_csv(valid_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "test_data = pd.read_csv(test_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "\n",
    "print(f'Train size: {train_data.shape}')\n",
    "print(f'Valid size: {valid_data.shape}')\n",
    "print(f'Test size: {test_data.shape}')\n",
    "\n",
    "# display(train_data.head())  # Uncomment if using Jupyter Notebook\n",
    "\n",
    "# Загрузка эмбеддингов пользователей\n",
    "with open('../data/emb/embeddings.json', 'r') as f:\n",
    "    user_embeddings = json.load(f)\n",
    "\n",
    "# Преобразование эмбеддингов пользователей в словарь для быстрого доступа\n",
    "user2embedding = {int(user['id']): user['embedding'] for user in user_embeddings}\n",
    "\n",
    "# Подготовка последовательностей для обучения, валидации и теста\n",
    "def prepare_sequences(data):\n",
    "    user_group = data.groupby('user_id')['item_id'].apply(list)\n",
    "    sequences = []\n",
    "    user_ids = []\n",
    "    for user_id, seq in user_group.items():\n",
    "        if len(seq) >= 2:  # Только пользователи с достаточной историей\n",
    "            sequences.append(seq)\n",
    "            user_ids.append(user_id)\n",
    "    return sequences, user_ids\n",
    "\n",
    "train_sequences, train_user_ids = prepare_sequences(train_data)\n",
    "valid_sequences, valid_user_ids = prepare_sequences(valid_data)\n",
    "test_sequences, test_user_ids = prepare_sequences(test_data)\n",
    "\n",
    "print(f'Количество пользователей в обучающем наборе: {len(train_sequences)}')\n",
    "print(f'Количество пользователей в валидационном наборе: {len(valid_sequences)}')\n",
    "print(f'Количество пользователей в тестовом наборе: {len(test_sequences)}')\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, sequences, user_ids, user_embeddings, num_items, max_len=50, num_negatives=100):\n",
    "        self.sequences = sequences\n",
    "        self.user_ids = user_ids\n",
    "        self.user_embeddings = user_embeddings\n",
    "        self.max_len = max_len\n",
    "        self.num_negatives = num_negatives\n",
    "        self.num_items = num_items\n",
    "        \n",
    "        # Создание словаря для быстрого поиска взаимодействий пользователя\n",
    "        self.user_interactions = {}\n",
    "        for user_id, seq in zip(self.user_ids, self.sequences):\n",
    "            self.user_interactions[user_id] = set(seq)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        user_id = self.user_ids[idx]\n",
    "\n",
    "        # Получение эмбеддинга пользователя\n",
    "        embedding = self.user_embeddings.get(user_id, [0.0] * 1536)  # Обработка отсутствующих эмбеддингов\n",
    "        user_emb = torch.tensor(embedding, dtype=torch.float)\n",
    "\n",
    "        # Паддинг последовательности\n",
    "        if len(seq) < self.max_len:\n",
    "            padded_seq = [0] * (self.max_len - len(seq)) + seq\n",
    "            seq_len = len(seq)\n",
    "        else:\n",
    "            padded_seq = seq[-self.max_len:]\n",
    "            seq_len = self.max_len\n",
    "\n",
    "        # Положительный пример (последний элемент последовательности)\n",
    "        pos_item = padded_seq[-1]\n",
    "\n",
    "        # Отрицательные примеры\n",
    "        neg_items = []\n",
    "        user_seen = self.user_interactions[user_id]\n",
    "        while len(neg_items) < self.num_negatives:\n",
    "            neg_item = random.randint(1, self.num_items)\n",
    "            if neg_item not in user_seen and neg_item not in neg_items:\n",
    "                neg_items.append(neg_item)\n",
    "\n",
    "        return {\n",
    "            'seq': torch.tensor(padded_seq, dtype=torch.long),\n",
    "            'seq_len': torch.tensor(seq_len, dtype=torch.long),\n",
    "            'user_emb': user_emb,\n",
    "            'pos_item': torch.tensor(pos_item, dtype=torch.long),\n",
    "            'neg_items': torch.tensor(neg_items, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Определение количества товаров\n",
    "num_items = max(train_data['item_id'].max(), valid_data['item_id'].max(), test_data['item_id'].max())\n",
    "\n",
    "# Создание датасетов и DataLoader\n",
    "train_dataset = MovieLensDataset(train_sequences, train_user_ids, user2embedding, num_items, max_len, num_negatives)\n",
    "valid_dataset = MovieLensDataset(valid_sequences, valid_user_ids, user2embedding, num_items, max_len, num_negatives)\n",
    "test_dataset = MovieLensDataset(test_sequences, test_user_ids, user2embedding, num_items, max_len, num_negatives)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Реализация класса LLM4SASRecWithAttention\n",
    "class LLM4SASRecWithAttention(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim=50, user_embedding_dim=1536, num_heads=2, num_layers=2, dropout=0.2, max_len=50):\n",
    "        super(LLM4SASRecWithAttention, self).__init__()\n",
    "        self.item_embedding = nn.Embedding(num_items + 1, embedding_dim, padding_idx=0)\n",
    "        self.position_embedding = nn.Embedding(max_len + 1, embedding_dim)  # +1 для пользовательского токена\n",
    "\n",
    "        # Сокращение размерности эмбеддингов пользователей\n",
    "        self.user_mlp = nn.Sequential(\n",
    "            nn.Linear(user_embedding_dim, embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim,\n",
    "                                                   nhead=num_heads,\n",
    "                                                   dropout=dropout,\n",
    "                                                   activation='relu')\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(embedding_dim, num_items + 1)\n",
    "\n",
    "    def forward(self, input_seq, seq_len, user_emb):\n",
    "        batch_size, seq_length = input_seq.size()\n",
    "\n",
    "        # Встраивание элементов и позиций\n",
    "        item_emb = self.item_embedding(input_seq) + self.position_embedding(\n",
    "            torch.arange(0, seq_length, device=input_seq.device).unsqueeze(0).expand_as(input_seq)\n",
    "        )\n",
    "\n",
    "        # Сокращение эмбеддингов пользователей\n",
    "        user_emb_compressed = self.user_mlp(user_emb)  # (batch_size, embedding_dim)\n",
    "\n",
    "        # Интеграция эмбеддингов пользователей через внимание\n",
    "        # Добавляем эмбеддинг пользователя в начало последовательности\n",
    "        user_emb_expanded = user_emb_compressed.unsqueeze(1)  # (batch_size, 1, embedding_dim)\n",
    "        combined_emb = torch.cat([user_emb_expanded, item_emb], dim=1)  # (batch_size, max_len + 1, embedding_dim)\n",
    "\n",
    "        combined_emb = self.layer_norm(combined_emb)\n",
    "        combined_emb = self.dropout(combined_emb)\n",
    "\n",
    "        # Трансформер ожидает вход размерности (seq_len, batch_size, embedding_dim)\n",
    "        combined_emb = combined_emb.transpose(0, 1)\n",
    "\n",
    "        # Создание маски для паддинга (игнорируем пользовательский токен)\n",
    "        mask = torch.cat([\n",
    "            torch.zeros((batch_size, 1), dtype=torch.bool, device=input_seq.device),\n",
    "            (input_seq == 0)\n",
    "        ], dim=1)  # (batch_size, max_len + 1)\n",
    "\n",
    "        # Пропуск через трансформер\n",
    "        output = self.transformer(combined_emb, src_key_padding_mask=mask)\n",
    "        output = output.transpose(0, 1)  # (batch_size, max_len + 1, embedding_dim)\n",
    "\n",
    "        # Использование последнего элемента последовательности (исключая пользовательский токен)\n",
    "        output = output[:, -1, :]  # (batch_size, embedding_dim)\n",
    "        logits = self.fc(output)    # (batch_size, num_items + 1)\n",
    "        return logits\n",
    "\n",
    "# Инициализация модели\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "embedding_dim = 50\n",
    "num_heads = 2\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "\n",
    "model = LLM4SASRecWithAttention(\n",
    "    num_items=num_items,\n",
    "    embedding_dim=embedding_dim,\n",
    "    user_embedding_dim=1536,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    max_len=max_len\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Инициализация весов (оптимизированная версия)\n",
    "def init_weights(m):\n",
    "    if isinstance(m, (nn.Linear, nn.Embedding)):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Критерий и оптимизатор\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Функции метрик\n",
    "def precision_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / len(relevant) if relevant else 0\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(recommended):\n",
    "        if item in relevant:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(relevant), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# Функция обучения\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        sequences = batch['seq'].to(device)\n",
    "        seq_lens = batch['seq_len'].to(device)\n",
    "        user_emb = batch['user_emb'].to(device)\n",
    "        pos_items = batch['pos_item'].to(device)\n",
    "        neg_items = batch['neg_items'].to(device)  # (batch_size, num_negatives)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Предсказание для всех товаров\n",
    "        logits = model(sequences, seq_lens, user_emb)  # (batch_size, num_items + 1)\n",
    "\n",
    "        # Собираем логиты для положительных и негативных товаров\n",
    "        pos_logits = logits.gather(1, pos_items.view(-1, 1))  # (batch_size, 1)\n",
    "        neg_logits = logits.gather(1, neg_items)  # (batch_size, num_negatives)\n",
    "\n",
    "        # Создание меток\n",
    "        pos_labels = torch.ones(pos_logits.size(0), 1).to(device)  # (batch_size, 1)\n",
    "        neg_labels = torch.zeros(neg_logits.size(0), neg_logits.size(1)).to(device)  # (batch_size, num_negatives)\n",
    "\n",
    "        # Объединение логитов и меток\n",
    "        combined_logits = torch.cat([pos_logits, neg_logits], dim=1)  # (batch_size, 1 + num_negatives)\n",
    "        combined_labels = torch.cat([pos_labels, neg_labels], dim=1)  # (batch_size, 1 + num_negatives)\n",
    "\n",
    "        # Вычисление потерь\n",
    "        loss = criterion(combined_logits, combined_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Функция валидации\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences = batch['seq'].to(device)\n",
    "            seq_lens = batch['seq_len'].to(device)\n",
    "            user_emb = batch['user_emb'].to(device)\n",
    "            pos_items = batch['pos_item'].to(device)\n",
    "            neg_items = batch['neg_items'].to(device)\n",
    "\n",
    "            # Предсказание для всех товаров\n",
    "            logits = model(sequences, seq_lens, user_emb)\n",
    "\n",
    "            # Собираем логиты для положительных и негативных товаров\n",
    "            pos_logits = logits.gather(1, pos_items.view(-1, 1))  # (batch_size, 1)\n",
    "            neg_logits = logits.gather(1, neg_items)  # (batch_size, num_negatives)\n",
    "\n",
    "            # Создание меток\n",
    "            pos_labels = torch.ones(pos_logits.size(0), 1).to(device)  # (batch_size, 1)\n",
    "            neg_labels = torch.zeros(neg_logits.size(0), neg_logits.size(1)).to(device)  # (batch_size, num_negatives)\n",
    "\n",
    "            # Объединение логитов и меток\n",
    "            combined_logits = torch.cat([pos_logits, neg_logits], dim=1)  # (batch_size, 1 + num_negatives)\n",
    "            combined_labels = torch.cat([pos_labels, neg_labels], dim=1)  # (batch_size, 1 + num_negatives)\n",
    "\n",
    "            # Вычисление потерь\n",
    "            loss = criterion(combined_logits, combined_labels)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Цикл обучения с валидацией\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    valid_loss = validate(model, valid_loader, criterion, device)\n",
    "    print(f'Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}')\n",
    "\n",
    "# Функция оценки\n",
    "def evaluate(model, loader, device, k=10):\n",
    "    model.eval()\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    ndcg_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences = batch['seq'].to(device)\n",
    "            seq_lens = batch['seq_len'].to(device)\n",
    "            user_emb = batch['user_emb'].to(device)\n",
    "            pos_items = batch['pos_item'].to(device)\n",
    "            # neg_items = batch['neg_items'].to(device)  # Негативные примеры не нужны для метрик\n",
    "\n",
    "            # Получение предсказаний\n",
    "            logits = model(sequences, seq_lens, user_emb)  # (batch_size, num_items + 1)\n",
    "            _, top_k_items = torch.topk(logits, k, dim=1)  # Получаем top-K предсказаний для каждого пользователя\n",
    "\n",
    "            # Цикл по батчу для расчета метрик\n",
    "            for i in range(sequences.size(0)):\n",
    "                recommended_items = top_k_items[i].cpu().numpy()\n",
    "                relevant_items = [pos_items[i].item()]\n",
    "\n",
    "                precision_scores.append(precision_at_k(recommended_items, relevant_items, k))\n",
    "                recall_scores.append(recall_at_k(recommended_items, relevant_items, k))\n",
    "                ndcg_scores.append(ndcg_at_k(recommended_items, relevant_items, k))\n",
    "\n",
    "    # Среднее значение метрик по всем пользователям\n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    mean_ndcg = np.mean(ndcg_scores)\n",
    "\n",
    "    return mean_precision, mean_recall, mean_ndcg\n",
    "\n",
    "# Параметр K для top-K рекомендаций\n",
    "k = 10\n",
    "\n",
    "# Оценка модели\n",
    "precision, recall, ndcg = evaluate(model, test_loader, device, k=k)\n",
    "print(f'Precision@{k}: {precision:.4f}')\n",
    "print(f'Recall@{k}: {recall:.4f}')\n",
    "print(f'NDCG@{k}: {ndcg:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (697378, 4)\n",
      "Valid size: (99582, 4)\n",
      "Test size: (203165, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>978300019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>978300103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1     3186       4  978300019\n",
       "1        1     1721       4  978300055\n",
       "2        1     1022       5  978300055\n",
       "3        1     1270       5  978300055\n",
       "4        1     2340       3  978300103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пользователей в обучающем наборе: 6040\n",
      "Количество пользователей в валидационном наборе: 5954\n",
      "Количество пользователей в тестовом наборе: 6040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\redpo\\Desktop\\sasrec-bert4rec-recsys23\\.venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 7.7982, Valid Loss: 6.9893\n",
      "Epoch 2/10, Train Loss: 6.3304, Valid Loss: 5.7871\n",
      "Epoch 3/10, Train Loss: 5.1220, Valid Loss: 4.6419\n",
      "Epoch 4/10, Train Loss: 3.9420, Valid Loss: 3.6762\n",
      "Epoch 5/10, Train Loss: 3.0102, Valid Loss: 2.9548\n",
      "Epoch 6/10, Train Loss: 2.2916, Valid Loss: 2.4405\n",
      "Epoch 7/10, Train Loss: 1.7354, Valid Loss: 2.0537\n",
      "Epoch 8/10, Train Loss: 1.3116, Valid Loss: 1.8192\n",
      "Epoch 9/10, Train Loss: 1.0076, Valid Loss: 1.6616\n",
      "Epoch 10/10, Train Loss: 0.7750, Valid Loss: 1.5123\n",
      "Precision@10: 0.0846\n",
      "Recall@10: 0.8455\n",
      "NDCG@10: 0.8395\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Параметры\n",
    "max_len = 50\n",
    "batch_size = 128\n",
    "\n",
    "# Файлы данных\n",
    "train_file = '../data/source/1_ml-1m_original.part1.inter'\n",
    "valid_file = '../data/source/1_ml-1m_original.part2.inter'\n",
    "test_file = '../data/source/1_ml-1m_original.part3.inter'\n",
    "\n",
    "# Загрузка данных\n",
    "train_data = pd.read_csv(train_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "valid_data = pd.read_csv(valid_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "test_data = pd.read_csv(test_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "\n",
    "print(f'Train size: {train_data.shape}')\n",
    "print(f'Valid size: {valid_data.shape}')\n",
    "print(f'Test size: {test_data.shape}')\n",
    "\n",
    "display(train_data.head())\n",
    "\n",
    "# Загрузка эмбеддингов пользователей\n",
    "with open('../data/emb/embeddings.json', 'r') as f:\n",
    "    user_embeddings = json.load(f)\n",
    "\n",
    "# Преобразование эмбеддингов пользователей в словарь для быстрого доступа\n",
    "user2embedding = {int(user['id']): user['embedding'] for user in user_embeddings}\n",
    "\n",
    "# Подготовка последовательностей для обучения, валидации и теста\n",
    "def prepare_sequences(data):\n",
    "    user_group = data.groupby('user_id')['item_id'].apply(list)\n",
    "    sequences = []\n",
    "    user_ids = []\n",
    "    for user_id, seq in user_group.items():\n",
    "        if len(seq) >= 2:  # Только пользователи с достаточной историей\n",
    "            sequences.append(seq)\n",
    "            user_ids.append(user_id)\n",
    "    return sequences, user_ids\n",
    "\n",
    "train_sequences, train_user_ids = prepare_sequences(train_data)\n",
    "valid_sequences, valid_user_ids = prepare_sequences(valid_data)\n",
    "test_sequences, test_user_ids = prepare_sequences(test_data)\n",
    "\n",
    "print(f'Количество пользователей в обучающем наборе: {len(train_sequences)}')\n",
    "print(f'Количество пользователей в валидационном наборе: {len(valid_sequences)}')\n",
    "print(f'Количество пользователей в тестовом наборе: {len(test_sequences)}')\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, sequences, user_ids, user_embeddings=None, max_len=50):\n",
    "        self.sequences = sequences\n",
    "        self.user_ids = user_ids\n",
    "        self.user_embeddings = user_embeddings\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        user_id = self.user_ids[idx]\n",
    "\n",
    "        if self.user_embeddings is not None:\n",
    "            embedding = self.user_embeddings.get(user_id, [0.0] * 1536)\n",
    "        else:\n",
    "            embedding = [0.0] * 1536\n",
    "\n",
    "        user_emb = torch.tensor(embedding, dtype=torch.float)\n",
    "\n",
    "        if len(seq) < self.max_len:\n",
    "            padded_seq = [0] * (self.max_len - len(seq)) + seq\n",
    "            seq_len = len(seq)\n",
    "        else:\n",
    "            padded_seq = seq[-self.max_len:]\n",
    "            seq_len = self.max_len\n",
    "\n",
    "        return torch.tensor(padded_seq, dtype=torch.long), torch.tensor(seq_len, dtype=torch.long), user_emb\n",
    "\n",
    "# Создание датасетов\n",
    "train_dataset = MovieLensDataset(train_sequences, train_user_ids, user2embedding, max_len)\n",
    "valid_dataset = MovieLensDataset(valid_sequences, valid_user_ids, None, max_len)  # Эмбеддинги не используются\n",
    "test_dataset = MovieLensDataset(test_sequences, test_user_ids, None, max_len)     # Эмбеддинги не используются\n",
    "\n",
    "# Создание DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Реализация DCNv2\n",
    "class CrossLayer(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CrossLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.weight = nn.Parameter(torch.randn(input_dim, 1))\n",
    "        self.bias = nn.Parameter(torch.randn(input_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, input_dim)\n",
    "        x_0 = x\n",
    "        x_l = torch.matmul(x, self.weight) + self.bias  # (batch_size, 1)\n",
    "        x_l = x_0 * x_l  # Broadcasting to (batch_size, input_dim)\n",
    "        return x_l\n",
    "\n",
    "class DCNv2(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers=2):\n",
    "        super(DCNv2, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.cross_layers = nn.ModuleList([CrossLayer(input_dim) for _ in range(num_layers)])\n",
    "        self.output_layer = nn.Linear(input_dim * (num_layers + 1), input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, input_dim)\n",
    "        x_0 = x\n",
    "        x_l = x\n",
    "        outputs = [x_0]\n",
    "        for cross_layer in self.cross_layers:\n",
    "            x_l = cross_layer(x_l)\n",
    "            outputs.append(x_l)\n",
    "        concatenated = torch.cat(outputs, dim=1)  # (batch_size, input_dim * (num_layers +1))\n",
    "        output = self.output_layer(concatenated)   # (batch_size, input_dim)\n",
    "        return output\n",
    "\n",
    "# Модифицированный класс LLM4SASRec с DCNv2\n",
    "class LLM4SASRecDCNv2(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim=50, user_embedding_dim=1536, num_heads=2, num_layers=2, dropout=0.2, max_len=50, cross_num_layers=2):\n",
    "        super(LLM4SASRecDCNv2, self).__init__()\n",
    "        self.item_embedding = nn.Embedding(num_items + 1, embedding_dim, padding_idx=0)\n",
    "        self.position_embedding = nn.Embedding(max_len, embedding_dim)\n",
    "        \n",
    "        # Замена MLP на DCNv2 для обработки эмбеддингов пользователей\n",
    "        self.user_dcnv2 = DCNv2(user_embedding_dim, num_layers=cross_num_layers)\n",
    "        self.user_compress = nn.Linear(user_embedding_dim, embedding_dim)  # Преобразование размера после DCNv2\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Размер объединенного эмбеддинга\n",
    "        combined_dim = embedding_dim * 2\n",
    "        \n",
    "        # Слои трансформера с обновленной размерностью\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=combined_dim,\n",
    "                                                   nhead=num_heads,\n",
    "                                                   dropout=dropout,\n",
    "                                                   activation='relu')\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(combined_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(combined_dim, num_items + 1)\n",
    "    \n",
    "    def forward(self, input_seq, seq_len, user_emb):\n",
    "        # Встраивание элементов и позиций\n",
    "        item_emb = self.item_embedding(input_seq) + self.position_embedding(\n",
    "            torch.arange(0, input_seq.size(1), device=input_seq.device).unsqueeze(0).expand_as(input_seq)\n",
    "        )\n",
    "        \n",
    "        # Обработка эмбеддингов пользователей через DCNv2\n",
    "        user_emb_processed = self.user_dcnv2(user_emb)  # (batch_size, user_embedding_dim)\n",
    "        user_emb_compressed = self.user_compress(user_emb_processed)  # (batch_size, embedding_dim)\n",
    "        user_emb_compressed = self.relu(user_emb_compressed)  # Нелинейность\n",
    "        \n",
    "        user_emb_expanded = user_emb_compressed.unsqueeze(1).repeat(1, input_seq.size(1), 1)  # (batch_size, max_len, embedding_dim)\n",
    "        \n",
    "        # Конкатенация эмбеддингов элементов и пользователей\n",
    "        combined_emb = torch.cat([item_emb, user_emb_expanded], dim=-1)  # (batch_size, max_len, combined_dim)\n",
    "        \n",
    "        combined_emb = self.layer_norm(combined_emb)\n",
    "        combined_emb = self.dropout(combined_emb)\n",
    "        \n",
    "        # Трансформер ожидает вход размерности (seq_len, batch_size, embedding_dim)\n",
    "        combined_emb = combined_emb.transpose(0, 1)\n",
    "        \n",
    "        # Создание маски для паддинга\n",
    "        mask = (input_seq == 0)  # (batch_size, max_len)\n",
    "        \n",
    "        # Пропуск через трансформер\n",
    "        output = self.transformer(combined_emb, src_key_padding_mask=mask)\n",
    "        output = output.transpose(0, 1)  # (batch_size, max_len, combined_dim)\n",
    "        \n",
    "        # Использование последнего элемента последовательности\n",
    "        output = output[:, -1, :]  # (batch_size, combined_dim)\n",
    "        logits = self.fc(output)    # (batch_size, num_items + 1)\n",
    "        return logits\n",
    "\n",
    "# Параметры модели\n",
    "embedding_dim = 50\n",
    "num_heads = 2\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "cross_num_layers = 2  # Количество слоев в DCNv2\n",
    "\n",
    "num_items = max(train_data['item_id'].max(), valid_data['item_id'].max(), test_data['item_id'].max())\n",
    "\n",
    "model = LLM4SASRecDCNv2(\n",
    "    num_items=num_items,\n",
    "    embedding_dim=embedding_dim,\n",
    "    user_embedding_dim=1536,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    max_len=max_len,\n",
    "    cross_num_layers=cross_num_layers\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Критерий и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Игнорируем паддинг\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Функции метрик (оставляем без изменений)\n",
    "def precision_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / len(relevant) if relevant else 0\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(recommended):\n",
    "        if item in relevant:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(relevant), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# Функция обучения\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        sequences, lengths, user_emb = batch\n",
    "        sequences = sequences.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        user_emb = user_emb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences, lengths, user_emb)\n",
    "        targets = sequences[:, -1]  # Последний элемент последовательности\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Функция валидации (аналогично)\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, lengths, user_emb = batch\n",
    "            sequences = sequences.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            user_emb = user_emb.to(device)\n",
    "\n",
    "            outputs = model(sequences, lengths, user_emb)\n",
    "            targets = sequences[:, -1]\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Цикл обучения с валидацией\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    valid_loss = validate(model, valid_loader, criterion, device)\n",
    "    print(f'Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}')\n",
    "\n",
    "# Функция оценки\n",
    "def evaluate(model, loader, device, k=10):\n",
    "    model.eval()\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    ndcg_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, lengths, user_emb = batch\n",
    "            sequences = sequences.to(device)\n",
    "            user_emb = user_emb.to(device)\n",
    "            targets = sequences[:, -1]  # Последний элемент, который нужно предсказать\n",
    "\n",
    "            # Получение предсказаний\n",
    "            outputs = model(sequences, lengths, user_emb)  # (batch_size, num_items + 1)\n",
    "            _, top_k_items = torch.topk(outputs, k, dim=1)  # Получаем top-K предсказаний для каждого пользователя\n",
    "\n",
    "            # Цикл по батчу для расчета метрик\n",
    "            for i in range(sequences.size(0)):\n",
    "                recommended_items = top_k_items[i].cpu().numpy()\n",
    "                relevant_items = [targets[i].item()]\n",
    "\n",
    "                precision_scores.append(precision_at_k(recommended_items, relevant_items, k))\n",
    "                recall_scores.append(recall_at_k(recommended_items, relevant_items, k))\n",
    "                ndcg_scores.append(ndcg_at_k(recommended_items, relevant_items, k))\n",
    "\n",
    "    # Среднее значение метрик по всем пользователям\n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    mean_ndcg = np.mean(ndcg_scores)\n",
    "\n",
    "    return mean_precision, mean_recall, mean_ndcg\n",
    "\n",
    "# Параметр K для top-K рекомендаций\n",
    "k = 10\n",
    "\n",
    "# Оценка модели\n",
    "precision, recall, ndcg = evaluate(model, test_loader, device, k=k)\n",
    "print(f'Precision@{k}: {precision:.4f}')\n",
    "print(f'Recall@{k}: {recall:.4f}')\n",
    "print(f'NDCG@{k}: {ndcg:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (697378, 4)\n",
      "Valid size: (99582, 4)\n",
      "Test size: (203165, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>978300019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>978300103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1     3186       4  978300019\n",
       "1        1     1721       4  978300055\n",
       "2        1     1022       5  978300055\n",
       "3        1     1270       5  978300055\n",
       "4        1     2340       3  978300103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пользователей в обучающем наборе: 6040\n",
      "Количество пользователей в валидационном наборе: 5954\n",
      "Количество пользователей в тестовом наборе: 6040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\redpo\\Desktop\\sasrec-bert4rec-recsys23\\.venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 7.7958, Valid Loss: 6.9727\n",
      "Epoch 2/10, Train Loss: 6.3182, Valid Loss: 5.8482\n",
      "Epoch 3/10, Train Loss: 5.1111, Valid Loss: 4.6406\n",
      "Epoch 4/10, Train Loss: 3.9817, Valid Loss: 3.6352\n",
      "Epoch 5/10, Train Loss: 3.0220, Valid Loss: 2.8984\n",
      "Epoch 6/10, Train Loss: 2.2765, Valid Loss: 2.4139\n",
      "Epoch 7/10, Train Loss: 1.7272, Valid Loss: 2.0767\n",
      "Epoch 8/10, Train Loss: 1.3205, Valid Loss: 1.8131\n",
      "Epoch 9/10, Train Loss: 1.0260, Valid Loss: 1.6570\n",
      "Epoch 10/10, Train Loss: 0.7747, Valid Loss: 1.5599\n",
      "Precision@10: 0.0845\n",
      "Recall@10: 0.8454\n",
      "NDCG@10: 0.8370\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Параметры\n",
    "max_len = 50\n",
    "batch_size = 128\n",
    "\n",
    "# Файлы данных\n",
    "train_file = '../data/source/1_ml-1m_original.part1.inter'\n",
    "valid_file = '../data/source/1_ml-1m_original.part2.inter'\n",
    "test_file = '../data/source/1_ml-1m_original.part3.inter'\n",
    "\n",
    "# Загрузка данных\n",
    "train_data = pd.read_csv(train_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "valid_data = pd.read_csv(valid_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "test_data = pd.read_csv(test_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "\n",
    "print(f'Train size: {train_data.shape}')\n",
    "print(f'Valid size: {valid_data.shape}')\n",
    "print(f'Test size: {test_data.shape}')\n",
    "\n",
    "display(train_data.head())\n",
    "\n",
    "# Загрузка эмбеддингов пользователей\n",
    "with open('../data/emb/embeddings.json', 'r') as f:\n",
    "    user_embeddings = json.load(f)\n",
    "\n",
    "# Преобразование эмбеддингов пользователей в словарь для быстрого доступа\n",
    "user2embedding = {int(user['id']): user['embedding'] for user in user_embeddings}\n",
    "\n",
    "# Подготовка последовательностей для обучения, валидации и теста\n",
    "def prepare_sequences(data):\n",
    "    user_group = data.groupby('user_id')['item_id'].apply(list)\n",
    "    sequences = []\n",
    "    user_ids = []\n",
    "    for user_id, seq in user_group.items():\n",
    "        if len(seq) >= 2:  # Только пользователи с достаточной историей\n",
    "            sequences.append(seq)\n",
    "            user_ids.append(user_id)\n",
    "    return sequences, user_ids\n",
    "\n",
    "train_sequences, train_user_ids = prepare_sequences(train_data)\n",
    "valid_sequences, valid_user_ids = prepare_sequences(valid_data)\n",
    "test_sequences, test_user_ids = prepare_sequences(test_data)\n",
    "\n",
    "print(f'Количество пользователей в обучающем наборе: {len(train_sequences)}')\n",
    "print(f'Количество пользователей в валидационном наборе: {len(valid_sequences)}')\n",
    "print(f'Количество пользователей в тестовом наборе: {len(test_sequences)}')\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, sequences, user_ids, user_embeddings=None, max_len=50):\n",
    "        self.sequences = sequences\n",
    "        self.user_ids = user_ids\n",
    "        self.user_embeddings = user_embeddings\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        user_id = self.user_ids[idx]\n",
    "\n",
    "        if self.user_embeddings is not None:\n",
    "            embedding = self.user_embeddings.get(user_id, [0.0] * 1536)\n",
    "        else:\n",
    "            embedding = [0.0] * 1536\n",
    "\n",
    "        user_emb = torch.tensor(embedding, dtype=torch.float)\n",
    "\n",
    "        if len(seq) < self.max_len:\n",
    "            padded_seq = [0] * (self.max_len - len(seq)) + seq\n",
    "            seq_len = len(seq)\n",
    "        else:\n",
    "            padded_seq = seq[-self.max_len:]\n",
    "            seq_len = self.max_len\n",
    "\n",
    "        return torch.tensor(padded_seq, dtype=torch.long), torch.tensor(seq_len, dtype=torch.long), user_emb\n",
    "\n",
    "# Создание датасетов\n",
    "train_dataset = MovieLensDataset(train_sequences, train_user_ids, user2embedding, max_len)\n",
    "valid_dataset = MovieLensDataset(valid_sequences, valid_user_ids, None, max_len)  # Эмбеддинги не используются\n",
    "test_dataset = MovieLensDataset(test_sequences, test_user_ids, None, max_len)     # Эмбеддинги не используются\n",
    "\n",
    "# Создание DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Реализация DCNv2\n",
    "class CrossLayer(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CrossLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.weight = nn.Parameter(torch.randn(input_dim, 1))\n",
    "        self.bias = nn.Parameter(torch.randn(input_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, input_dim)\n",
    "        x_0 = x\n",
    "        x_l = torch.matmul(x, self.weight) + self.bias  # (batch_size, 1)\n",
    "        x_l = x_0 * x_l  # Broadcasting to (batch_size, input_dim)\n",
    "        return x_l\n",
    "\n",
    "class DCNv2(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers=2):\n",
    "        super(DCNv2, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.cross_layers = nn.ModuleList([CrossLayer(input_dim) for _ in range(num_layers)])\n",
    "        self.output_layer = nn.Linear(input_dim * (num_layers + 1), input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, input_dim)\n",
    "        x_0 = x\n",
    "        x_l = x\n",
    "        outputs = [x_0]\n",
    "        for cross_layer in self.cross_layers:\n",
    "            x_l = cross_layer(x_l)\n",
    "            outputs.append(x_l)\n",
    "        concatenated = torch.cat(outputs, dim=1)  # (batch_size, input_dim * (num_layers +1))\n",
    "        output = self.output_layer(concatenated)   # (batch_size, input_dim)\n",
    "        return output\n",
    "\n",
    "# Отдельный модуль внимания для пользовательских эмбеддингов\n",
    "class UserAttention(nn.Module):\n",
    "    def __init__(self, user_embedding_dim, attention_dim):\n",
    "        super(UserAttention, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=user_embedding_dim, num_heads=1, batch_first=True)\n",
    "        self.linear = nn.Linear(user_embedding_dim, attention_dim)\n",
    "\n",
    "    def forward(self, user_emb):\n",
    "        # user_emb: (batch_size, user_embedding_dim)\n",
    "        # Добавляем временную размерность\n",
    "        user_emb = user_emb.unsqueeze(1)  # (batch_size, 1, user_embedding_dim)\n",
    "        attn_output, _ = self.attention(user_emb, user_emb, user_emb)  # (batch_size, 1, user_embedding_dim)\n",
    "        attn_output = attn_output.squeeze(1)  # (batch_size, user_embedding_dim)\n",
    "        attn_output = self.linear(attn_output)  # (batch_size, attention_dim)\n",
    "        return attn_output\n",
    "\n",
    "# Модифицированный класс LLM4SASRec с DCNv2 и отдельным вниманием для пользователей\n",
    "class LLM4SASRecDCNv2(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim=50, user_embedding_dim=1536, num_heads=2, num_layers=2, dropout=0.2, max_len=50, cross_num_layers=2, attention_dim=50):\n",
    "        super(LLM4SASRecDCNv2, self).__init__()\n",
    "        self.item_embedding = nn.Embedding(num_items + 1, embedding_dim, padding_idx=0)\n",
    "        self.position_embedding = nn.Embedding(max_len, embedding_dim)\n",
    "        \n",
    "        # Модуль DCNv2 для обработки пользовательских эмбеддингов\n",
    "        self.user_dcnv2 = DCNv2(user_embedding_dim, num_layers=cross_num_layers)\n",
    "        self.user_compress = nn.Linear(user_embedding_dim, embedding_dim)  # Преобразование размера после DCNv2\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Отдельный модуль внимания для пользовательских эмбеддингов\n",
    "        self.user_attention = UserAttention(user_embedding_dim=embedding_dim, attention_dim=attention_dim)\n",
    "        \n",
    "        # Размер объединенного эмбеддинга после интеграции внимания\n",
    "        combined_dim = embedding_dim + attention_dim\n",
    "        \n",
    "        # Слои трансформера с обновленной размерностью\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=combined_dim,\n",
    "                                                   nhead=num_heads,\n",
    "                                                   dropout=dropout,\n",
    "                                                   activation='relu')\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(combined_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(combined_dim, num_items + 1)\n",
    "    \n",
    "    def forward(self, input_seq, seq_len, user_emb):\n",
    "        # Встраивание элементов и позиций\n",
    "        item_emb = self.item_embedding(input_seq) + self.position_embedding(\n",
    "            torch.arange(0, input_seq.size(1), device=input_seq.device).unsqueeze(0).expand_as(input_seq)\n",
    "        )\n",
    "        \n",
    "        # Обработка эмбеддингов пользователей через DCNv2\n",
    "        user_emb_processed = self.user_dcnv2(user_emb)  # (batch_size, user_embedding_dim)\n",
    "        user_emb_compressed = self.user_compress(user_emb_processed)  # (batch_size, embedding_dim)\n",
    "        user_emb_compressed = self.relu(user_emb_compressed)  # Нелинейность\n",
    "        \n",
    "        # Применение отдельного внимания к пользовательским эмбеддингам\n",
    "        user_attn = self.user_attention(user_emb_compressed)  # (batch_size, attention_dim)\n",
    "        \n",
    "        # Конкатенация эмбеддингов элементов и пользовательского внимания\n",
    "        combined_emb = torch.cat([item_emb, user_attn.unsqueeze(1).repeat(1, input_seq.size(1), 1)], dim=-1)  # (batch_size, max_len, combined_dim)\n",
    "        \n",
    "        combined_emb = self.layer_norm(combined_emb)\n",
    "        combined_emb = self.dropout(combined_emb)\n",
    "        \n",
    "        # Трансформер ожидает вход размерности (seq_len, batch_size, embedding_dim)\n",
    "        combined_emb = combined_emb.transpose(0, 1)\n",
    "        \n",
    "        # Создание маски для паддинга\n",
    "        mask = (input_seq == 0)  # (batch_size, max_len)\n",
    "        \n",
    "        # Пропуск через трансформер\n",
    "        output = self.transformer(combined_emb, src_key_padding_mask=mask)\n",
    "        output = output.transpose(0, 1)  # (batch_size, max_len, combined_dim)\n",
    "        \n",
    "        # Использование последнего элемента последовательности\n",
    "        output = output[:, -1, :]  # (batch_size, combined_dim)\n",
    "        logits = self.fc(output)    # (batch_size, num_items + 1)\n",
    "        return logits\n",
    "\n",
    "# Параметры модели\n",
    "embedding_dim = 50\n",
    "attention_dim = 50  # Должно соответствовать embedding_dim для простоты\n",
    "num_heads = 2\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "cross_num_layers = 2  # Количество слоев в DCNv2\n",
    "\n",
    "num_items = max(train_data['item_id'].max(), valid_data['item_id'].max(), test_data['item_id'].max())\n",
    "\n",
    "model = LLM4SASRecDCNv2(\n",
    "    num_items=num_items,\n",
    "    embedding_dim=embedding_dim,\n",
    "    user_embedding_dim=1536,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    max_len=max_len,\n",
    "    cross_num_layers=cross_num_layers,\n",
    "    attention_dim=attention_dim\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Критерий и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Игнорируем паддинг\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Функции метрик (оставляем без изменений)\n",
    "def precision_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / len(relevant) if relevant else 0\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(recommended):\n",
    "        if item in relevant:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(relevant), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# Функция обучения\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        sequences, lengths, user_emb = batch\n",
    "        sequences = sequences.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        user_emb = user_emb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences, lengths, user_emb)\n",
    "        targets = sequences[:, -1]  # Последний элемент последовательности\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Функция валидации (аналогично)\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, lengths, user_emb = batch\n",
    "            sequences = sequences.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            user_emb = user_emb.to(device)\n",
    "\n",
    "            outputs = model(sequences, lengths, user_emb)\n",
    "            targets = sequences[:, -1]\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Цикл обучения с валидацией\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    valid_loss = validate(model, valid_loader, criterion, device)\n",
    "    print(f'Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}')\n",
    "\n",
    "# Функция оценки\n",
    "def evaluate(model, loader, device, k=10):\n",
    "    model.eval()\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    ndcg_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, lengths, user_emb = batch\n",
    "            sequences = sequences.to(device)\n",
    "            user_emb = user_emb.to(device)\n",
    "            targets = sequences[:, -1]  # Последний элемент, который нужно предсказать\n",
    "\n",
    "            # Получение предсказаний\n",
    "            outputs = model(sequences, lengths, user_emb)  # (batch_size, num_items + 1)\n",
    "            _, top_k_items = torch.topk(outputs, k, dim=1)  # Получаем top-K предсказаний для каждого пользователя\n",
    "\n",
    "            # Цикл по батчу для расчета метрик\n",
    "            for i in range(sequences.size(0)):\n",
    "                recommended_items = top_k_items[i].cpu().numpy()\n",
    "                relevant_items = [targets[i].item()]\n",
    "\n",
    "                precision_scores.append(precision_at_k(recommended_items, relevant_items, k))\n",
    "                recall_scores.append(recall_at_k(recommended_items, relevant_items, k))\n",
    "                ndcg_scores.append(ndcg_at_k(recommended_items, relevant_items, k))\n",
    "\n",
    "    # Среднее значение метрик по всем пользователям\n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    mean_ndcg = np.mean(ndcg_scores)\n",
    "\n",
    "    return mean_precision, mean_recall, mean_ndcg\n",
    "\n",
    "# Параметр K для top-K рекомендаций\n",
    "k = 10\n",
    "\n",
    "# Оценка модели\n",
    "precision, recall, ndcg = evaluate(model, test_loader, device, k=k)\n",
    "print(f'Precision@{k}: {precision:.4f}')\n",
    "print(f'Recall@{k}: {recall:.4f}')\n",
    "print(f'NDCG@{k}: {ndcg:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (697378, 4)\n",
      "Valid size: (99582, 4)\n",
      "Test size: (203165, 4)\n",
      "Количество пользователей в обучающем наборе: 6040\n",
      "Количество пользователей в валидационном наборе: 5954\n",
      "Количество пользователей в тестовом наборе: 6040\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "\n",
    "# Параметры\n",
    "max_len = 50\n",
    "batch_size = 128\n",
    "\n",
    "# Файлы данных\n",
    "train_file = '../data/source/1_ml-1m_original.part1.inter'\n",
    "valid_file = '../data/source/1_ml-1m_original.part2.inter'\n",
    "test_file = '../data/source/1_ml-1m_original.part3.inter'\n",
    "\n",
    "# Загрузка данных\n",
    "train_data = pd.read_csv(train_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "valid_data = pd.read_csv(valid_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "test_data = pd.read_csv(test_file, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'], skiprows=1)\n",
    "\n",
    "print(f'Train size: {train_data.shape}')\n",
    "print(f'Valid size: {valid_data.shape}')\n",
    "print(f'Test size: {test_data.shape}')\n",
    "\n",
    "# Загрузка эмбеддингов пользователей\n",
    "with open('../data/emb/embeddings.json', 'r') as f:\n",
    "    user_embeddings = json.load(f)\n",
    "\n",
    "# Преобразование эмбеддингов пользователей в словарь для быстрого доступа\n",
    "user2embedding = {int(user['id']): user['embedding'] for user in user_embeddings}\n",
    "\n",
    "# Подготовка последовательностей для обучения, валидации и теста\n",
    "def prepare_sequences(data):\n",
    "    user_group = data.groupby('user_id')['item_id'].apply(list)\n",
    "    sequences = []\n",
    "    user_ids = []\n",
    "    for user_id, seq in user_group.items():\n",
    "        if len(seq) >= 2:  # Только пользователи с достаточной историей\n",
    "            sequences.append(seq)\n",
    "            user_ids.append(user_id)\n",
    "    return sequences, user_ids\n",
    "\n",
    "train_sequences, train_user_ids = prepare_sequences(train_data)\n",
    "valid_sequences, valid_user_ids = prepare_sequences(valid_data)\n",
    "test_sequences, test_user_ids = prepare_sequences(test_data)\n",
    "\n",
    "print(f'Количество пользователей в обучающем наборе: {len(train_sequences)}')\n",
    "print(f'Количество пользователей в валидационном наборе: {len(valid_sequences)}')\n",
    "print(f'Количество пользователей в тестовом наборе: {len(test_sequences)}')\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, sequences, user_ids, user_embeddings=None, max_len=50):\n",
    "        self.sequences = sequences\n",
    "        self.user_ids = user_ids\n",
    "        self.user_embeddings = user_embeddings\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        user_id = self.user_ids[idx]\n",
    "\n",
    "        if self.user_embeddings is not None:\n",
    "            embedding = self.user_embeddings.get(user_id, [0.0] * 1536)\n",
    "        else:\n",
    "            embedding = [0.0] * 1536\n",
    "\n",
    "        user_emb = torch.tensor(embedding, dtype=torch.float)\n",
    "\n",
    "        if len(seq) < self.max_len:\n",
    "            padded_seq = [0] * (self.max_len - len(seq)) + seq\n",
    "            seq_len = len(seq)\n",
    "        else:\n",
    "            padded_seq = seq[-self.max_len:]\n",
    "            seq_len = self.max_len\n",
    "\n",
    "        return torch.tensor(padded_seq, dtype=torch.long), torch.tensor(seq_len, dtype=torch.long), user_emb\n",
    "\n",
    "# Создание датасетов\n",
    "train_dataset = MovieLensDataset(train_sequences, train_user_ids, user2embedding, max_len)\n",
    "valid_dataset = MovieLensDataset(valid_sequences, valid_user_ids, None, max_len)  # Эмбеддинги не используются\n",
    "test_dataset = MovieLensDataset(test_sequences, test_user_ids, None, max_len)     # Эмбеддинги не используются\n",
    "\n",
    "# Создание DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Реализация DCNv2\n",
    "class CrossLayer(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CrossLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.weight = nn.Parameter(torch.randn(input_dim, 1))\n",
    "        self.bias = nn.Parameter(torch.randn(input_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, input_dim)\n",
    "        x_0 = x\n",
    "        x_l = torch.matmul(x, self.weight) + self.bias  # (batch_size, 1)\n",
    "        x_l = x_0 * x_l  # Broadcasting to (batch_size, input_dim)\n",
    "        return x_l\n",
    "\n",
    "class DCNv2(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers=2):\n",
    "        super(DCNv2, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.cross_layers = nn.ModuleList([CrossLayer(input_dim) for _ in range(num_layers)])\n",
    "        self.output_layer = nn.Linear(input_dim * (num_layers + 1), input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, input_dim)\n",
    "        x_0 = x\n",
    "        x_l = x\n",
    "        outputs = [x_0]\n",
    "        for cross_layer in self.cross_layers:\n",
    "            x_l = cross_layer(x_l)\n",
    "            outputs.append(x_l)\n",
    "        concatenated = torch.cat(outputs, dim=1)  # (batch_size, input_dim * (num_layers +1))\n",
    "        output = self.output_layer(concatenated)   # (batch_size, input_dim)\n",
    "        return output\n",
    "\n",
    "# Кастомный слой трансформера\n",
    "class CustomTransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation='relu'):\n",
    "        super(CustomTransformerEncoderLayer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Стандартное многоголовое внимание\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "\n",
    "        # Отдельная голова внимания для пользовательских эмбеддингов\n",
    "        self.user_attn_q = nn.Linear(d_model, d_model // nhead, bias=False)\n",
    "        self.user_attn_k = nn.Linear(d_model, d_model // nhead, bias=False)\n",
    "        self.user_attn_v = nn.Linear(d_model, d_model // nhead, bias=False)\n",
    "        self.user_attn_out = nn.Linear(d_model // nhead, d_model, bias=False)\n",
    "        self.user_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Feedforward сеть\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout_fc = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        # Нормализация и Dropout\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        # Активация\n",
    "        self.activation = nn.ReLU() if activation == 'relu' else nn.GELU()\n",
    "\n",
    "    def forward(self, src, user_emb, src_mask=None, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        src: (seq_len, batch_size, d_model)\n",
    "        user_emb: (batch_size, d_model)\n",
    "        src_mask: (seq_len, seq_len)\n",
    "        src_key_padding_mask: (batch_size, seq_len)\n",
    "        \"\"\"\n",
    "        # Стандартное внимание\n",
    "        src2, _ = self.self_attn(src, src, src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask)\n",
    "        src = src + self.dropout1(src2)\n",
    "        src = self.norm1(src)\n",
    "\n",
    "        # Отдельная голова внимания для пользователей\n",
    "        Q_user = self.user_attn_q(user_emb)  # (batch_size, d_model//nhead)\n",
    "        K_user = self.user_attn_k(src.transpose(0,1))  # (batch_size, seq_len, d_model//nhead)\n",
    "        V_user = self.user_attn_v(src.transpose(0,1))  # (batch_size, seq_len, d_model//nhead)\n",
    "\n",
    "        Q_user = Q_user.unsqueeze(1)  # (batch_size, 1, d_model//nhead)\n",
    "\n",
    "        # Корректное вычисление весов внимания\n",
    "        attn_weights_user = torch.bmm(Q_user, K_user.transpose(1, 2)) / math.sqrt(self.d_model // self.nhead)  # (batch_size,1,seq_len)\n",
    "        attn_weights_user = F.softmax(attn_weights_user, dim=-1)  # (batch_size,1,seq_len)\n",
    "        attn_weights_user = self.user_dropout(attn_weights_user)\n",
    "\n",
    "        # Вычисляем выход внимания\n",
    "        attn_output_user = torch.bmm(attn_weights_user, V_user)  # (batch_size,1,d_model//nhead)\n",
    "        attn_output_user = attn_output_user.squeeze(1)  # (batch_size, d_model//nhead)\n",
    "\n",
    "        # Проекция обратно к d_model\n",
    "        attn_output_user = self.user_attn_out(attn_output_user)  # (batch_size, d_model)\n",
    "        attn_output_user = attn_output_user.unsqueeze(0)        # (1, batch_size, d_model)\n",
    "\n",
    "        # Добавление пользовательского внимания к src\n",
    "        src = src + self.dropout2(attn_output_user)\n",
    "        src = self.norm2(src)\n",
    "\n",
    "        # Feedforward сеть\n",
    "        src2 = self.linear2(self.dropout_fc(self.activation(self.linear1(src))))\n",
    "        src = src + self.dropout2(src2)\n",
    "        src = self.norm2(src)\n",
    "\n",
    "        return src\n",
    "\n",
    "class CustomTransformerEncoder(nn.Module):\n",
    "    def __init__(self, encoder_layer, num_layers):\n",
    "        super(CustomTransformerEncoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([encoder_layer for _ in range(num_layers)])\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, src, user_emb, mask=None, src_key_padding_mask=None):\n",
    "        for layer in self.layers:\n",
    "            src = layer(src, user_emb, mask, src_key_padding_mask)\n",
    "        return src\n",
    "\n",
    "# Модифицированный класс LLM4SASRec с DCNv2 и кастомным трансформером\n",
    "class LLM4SASRecDCNv2(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim=50, user_embedding_dim=1536, num_heads=2, num_layers=2, dropout=0.2, max_len=50, cross_num_layers=2):\n",
    "        super(LLM4SASRecDCNv2, self).__init__()\n",
    "        self.item_embedding = nn.Embedding(num_items + 1, embedding_dim, padding_idx=0)\n",
    "        self.position_embedding = nn.Embedding(max_len, embedding_dim)\n",
    "        \n",
    "        # Модуль DCNv2 для обработки пользовательских эмбеддингов\n",
    "        self.user_dcnv2 = DCNv2(user_embedding_dim, num_layers=cross_num_layers)\n",
    "        self.user_compress = nn.Linear(user_embedding_dim, embedding_dim)  # Преобразование размера после DCNv2\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Кастомный трансформер с отдельной головой внимания для пользователей\n",
    "        encoder_layer = CustomTransformerEncoderLayer(\n",
    "            d_model=embedding_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=2048,\n",
    "            dropout=dropout,\n",
    "            activation='relu'\n",
    "        )\n",
    "        self.transformer = CustomTransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(embedding_dim, num_items +1)\n",
    "    \n",
    "    def forward(self, input_seq, seq_len, user_emb):\n",
    "        \"\"\"\n",
    "        input_seq: (batch_size, max_len)\n",
    "        seq_len: (batch_size)\n",
    "        user_emb: (batch_size, user_embedding_dim)\n",
    "        \"\"\"\n",
    "        # Встраивание элементов и позиций\n",
    "        item_emb = self.item_embedding(input_seq) + self.position_embedding(\n",
    "            torch.arange(0, input_seq.size(1), device=input_seq.device).unsqueeze(0).expand_as(input_seq)\n",
    "        )  # (batch_size, max_len, embedding_dim)\n",
    "\n",
    "        # Обработка пользовательских эмбеддингов через DCNv2\n",
    "        user_emb_processed = self.user_dcnv2(user_emb)  # (batch_size, user_embedding_dim)\n",
    "        user_emb_compressed = self.user_compress(user_emb_processed)  # (batch_size, embedding_dim)\n",
    "        user_emb_compressed = self.relu(user_emb_compressed)  # (batch_size, embedding_dim)\n",
    "\n",
    "        # Подготовка входа для трансформера\n",
    "        # Трансформер ожидает (seq_len, batch_size, d_model)\n",
    "        transformer_input = item_emb.transpose(0,1)  # (max_len, batch_size, embedding_dim)\n",
    "\n",
    "        # Маска для паддинга\n",
    "        src_key_padding_mask = (input_seq == 0)  # (batch_size, max_len)\n",
    "\n",
    "        # Пропуск через трансформер\n",
    "        transformer_output = self.transformer(transformer_input, user_emb_compressed, \n",
    "                                             mask=None, \n",
    "                                             src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # Использование последнего токена\n",
    "        output = transformer_output[-1, :, :]  # (batch_size, embedding_dim)\n",
    "\n",
    "        # Финальный слой классификации\n",
    "        logits = self.fc(output)  # (batch_size, num_items +1)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 7.8687, Valid Loss: 7.2749\n",
      "Model saved at epoch 1\n",
      "Epoch 2/10, Train Loss: 6.6132, Valid Loss: 6.3840\n",
      "Model saved at epoch 2\n",
      "Epoch 3/10, Train Loss: 5.5554, Valid Loss: 5.4623\n",
      "Model saved at epoch 3\n",
      "Epoch 4/10, Train Loss: 4.5574, Valid Loss: 4.6141\n",
      "Model saved at epoch 4\n",
      "Epoch 5/10, Train Loss: 3.6621, Valid Loss: 3.8708\n",
      "Model saved at epoch 5\n",
      "Epoch 6/10, Train Loss: 2.9225, Valid Loss: 3.3164\n",
      "Model saved at epoch 6\n",
      "Epoch 7/10, Train Loss: 2.3426, Valid Loss: 2.8236\n",
      "Model saved at epoch 7\n",
      "Epoch 8/10, Train Loss: 1.8566, Valid Loss: 2.4935\n",
      "Model saved at epoch 8\n",
      "Epoch 9/10, Train Loss: 1.4814, Valid Loss: 2.2147\n",
      "Model saved at epoch 9\n",
      "Epoch 10/10, Train Loss: 1.1876, Valid Loss: 2.0135\n",
      "Model saved at epoch 10\n"
     ]
    }
   ],
   "source": [
    "# Параметры модели\n",
    "embedding_dim = 50\n",
    "num_heads = 2\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "cross_num_layers = 2  # Количество слоёв в DCNv2\n",
    "\n",
    "num_items = max(train_data['item_id'].max(), valid_data['item_id'].max(), test_data['item_id'].max())\n",
    "\n",
    "model = LLM4SASRecDCNv2(\n",
    "    num_items=num_items,\n",
    "    embedding_dim=embedding_dim,\n",
    "    user_embedding_dim=1536,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    max_len=max_len,\n",
    "    cross_num_layers=cross_num_layers\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Критерий и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Игнорируем паддинг\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Функции метрик\n",
    "def precision_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(relevant))\n",
    "    return hits / len(relevant) if relevant else 0\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k):\n",
    "    recommended = recommended[:k]\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(recommended):\n",
    "        if item in relevant:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(relevant), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# Функция обучения\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        sequences, lengths, user_emb = batch\n",
    "        sequences = sequences.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        user_emb = user_emb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences, lengths, user_emb)\n",
    "        targets = sequences[:, -1]  # Последний элемент последовательности\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Функция валидации\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, lengths, user_emb = batch\n",
    "            sequences = sequences.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            user_emb = user_emb.to(device)\n",
    "\n",
    "            outputs = model(sequences, lengths, user_emb)\n",
    "            targets = sequences[:, -1]\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Функция оценки\n",
    "def evaluate(model, loader, device, k=10):\n",
    "    model.eval()\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    ndcg_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            sequences, lengths, user_emb = batch\n",
    "            sequences = sequences.to(device)\n",
    "            user_emb = user_emb.to(device)\n",
    "            targets = sequences[:, -1]  # Последний элемент, который нужно предсказать\n",
    "\n",
    "            # Получение предсказаний\n",
    "            outputs = model(sequences, lengths, user_emb)  # (batch_size, num_items + 1)\n",
    "            _, top_k_items = torch.topk(outputs, k, dim=1)  # Получаем top-K предсказаний для каждого пользователя\n",
    "\n",
    "            # Цикл по батчу для расчета метрик\n",
    "            for i in range(sequences.size(0)):\n",
    "                recommended_items = top_k_items[i].cpu().numpy()\n",
    "                relevant_items = [targets[i].item()]\n",
    "\n",
    "                precision_scores.append(precision_at_k(recommended_items, relevant_items, k))\n",
    "                recall_scores.append(recall_at_k(recommended_items, relevant_items, k))\n",
    "                ndcg_scores.append(ndcg_at_k(recommended_items, relevant_items, k))\n",
    "\n",
    "    # Среднее значение метрик по всем пользователям\n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    mean_ndcg = np.mean(ndcg_scores)\n",
    "\n",
    "    return mean_precision, mean_recall, mean_ndcg\n",
    "\n",
    "# Цикл обучения с валидацией\n",
    "num_epochs = 10\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    valid_loss = validate_epoch(model, valid_loader, criterion, device)\n",
    "    print(f'Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}')\n",
    "    \n",
    "    # Сохранение модели с наилучшей валидационной потерей\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f'Model saved at epoch {epoch}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\redpo\\AppData\\Local\\Temp\\ipykernel_8160\\3594956257.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.0834\n",
      "Recall@10: 0.8339\n",
      "NDCG@10: 0.7941\n"
     ]
    }
   ],
   "source": [
    "# Загрузка лучшей модели\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Оценка модели на тестовом наборе\n",
    "precision, recall, ndcg = evaluate(model, test_loader, device, k=10)\n",
    "print(f'Precision@10: {precision:.4f}')\n",
    "print(f'Recall@10: {recall:.4f}')\n",
    "print(f'NDCG@10: {ndcg:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
