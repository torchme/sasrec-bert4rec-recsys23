{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-10T20:14:48.636441Z",
     "start_time": "2025-02-10T20:14:48.630022Z"
    }
   },
   "source": [
    "import json\n",
    "%cd ../../../"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nseverin/MyData/Projects/Science/LLM/sasrec-bert4rec-recsys23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nseverin/MyData/Projects/Science/LLM/sasrec-bert4rec-recsys23/venv/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T20:14:49.958829Z",
     "start_time": "2025-02-10T20:14:49.947372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from itertools import product\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "from src.experiment_tools.utils import read_text, save_text, read_json\n",
    "\n",
    "\n",
    "def generate_config_params(json_data):\n",
    "    res = []\n",
    "    for seed in SEEDS:\n",
    "        for dct in json_data:\n",
    "            cur_dct = deepcopy(dct)\n",
    "            cur_dct['seed'] = seed\n",
    "            if 'user_profile_embeddings_files' in cur_dct:\n",
    "                cur_dct['user_profile_embeddings_files'] = FILE_MAPPING[SPLIT_NAME]['user_profile_embeddings_files'][cur_dct['user_profile_embeddings_files']]\n",
    "                cur_dct['reconstruction_layer'] = int(cur_dct['reconstruction_layer'])\n",
    "                cur_dct['fine_tune_epoch'] = int(cur_dct['fine_tune_epoch'])\n",
    "            res.append(cur_dct)\n",
    "    return res\n",
    "\n",
    "\n",
    "def create_list_of_lists(k, N):\n",
    "    result = []\n",
    "    start = 0\n",
    "    while start < N:\n",
    "        end = min(start + k - 1, N)\n",
    "        result.append([start, end])\n",
    "        start += k\n",
    "    return result\n",
    "\n",
    "\n",
    "def create_config_files(generated_configs):\n",
    "    def fill_by_config_dict(config_base, config_vals):\n",
    "        for field in config_vals:\n",
    "            cur_val = config_vals[field]\n",
    "            if field not in config_base:\n",
    "                print(field)\n",
    "                raise Exception()\n",
    "            config_base = config_base.replace('{' + field + '}', f'{cur_val}')\n",
    "        return config_base\n",
    "\n",
    "    for config in generated_configs:\n",
    "        config_base = read_text(CONFIG_TEMPLATE_PATH)\n",
    "        config_base = fill_by_config_dict(config_base, PREDEFINED_PARAMS)\n",
    "        config_base = fill_by_config_dict(config_base, config)\n",
    "        config_base_for_file_save = {k:v for k,v in config.items()}\n",
    "        print(config_base_for_file_save['user_profile_embeddings_files'])\n",
    "        print('-------')\n",
    "        if 'user_profile_embeddings_files' in config_base_for_file_save:\n",
    "            if isinstance(config_base_for_file_save['user_profile_embeddings_files'], list):\n",
    "                emb_name = FILE_TO_EMB_NAME[tuple(config_base_for_file_save['user_profile_embeddings_files'])]\n",
    "            else:\n",
    "                emb_name = FILE_TO_EMB_NAME[config_base_for_file_save['user_profile_embeddings_files']]\n",
    "            config_base_for_file_save['user_profile_embeddings_files'] = emb_name\n",
    "        save_path = SAVE_CONFIG_FILE.format(**config_base_for_file_save)\n",
    "        save_text(save_path, config_base)\n",
    "\n",
    "\n",
    "def create_bash(start, end):\n",
    "    base_bash = read_text(BASH_TEMPLATE_PATH)\n",
    "    base_bash = ((base_bash.replace('{start}', str(start))\n",
    "                 .replace('{end}', str(end)))\n",
    "                 .replace('{folder_path}', CONFIG_PATH))\n",
    "    save_text(os.path.join(BASH_PATH, f'{start}-{end}.sh'), base_bash)\n",
    "\n",
    "\n",
    "def create_bash_files(generated_confs, n_confs_per_bash):\n",
    "    ind_lst = create_list_of_lists(n_confs_per_bash, len(generated_confs))\n",
    "    print(len(ind_lst))\n",
    "    for start, end in ind_lst:\n",
    "        create_bash(start, end)\n",
    "\n",
    "\n",
    "def create_sbatch_files():\n",
    "    sbatch_temp = read_text(SBATCH_TEMPLATE_PATH)\n",
    "\n",
    "    for file in os.listdir(BASH_PATH):\n",
    "        cur_sbatch = (sbatch_temp.\n",
    "                      replace('{model_name}', MODEL_NAME).\n",
    "                      replace('{dataset}', DATASET).\n",
    "                      replace('{time_to_take}', TIME_TO_TAKE).\n",
    "                      replace('{artefact_path}', ARTEFACT_PATH).\n",
    "                      replace('{experiment_name}', EXPERIMENT_NAME).\n",
    "                      replace('{seed_folder}', SEED_FOLDER).\n",
    "                      replace('{bash_name}', file))\n",
    "        if file[0] == '.':\n",
    "            continue\n",
    "        save_text(os.path.join(SBATCH_PATH, file.replace('.sh', '.sbatch')), cur_sbatch)\n",
    "\n",
    "\n",
    "SBATCH_TEMPLATE_PATH = 'experiments-2_0/sbatch/BASE.sbatch'\n",
    "BASH_TEMPLATE_PATH = 'experiments-2_0/bash/BASE.sh'\n",
    "FILE_MAPPING_PATH = 'experiments-2_0/configs/file_mapping'"
   ],
   "id": "2f8ade711a1142f1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T19:00:02.251823Z",
     "start_time": "2025-02-04T19:00:02.248210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# BASELINE MODE\n",
    "\n",
    "MODEL_NAME = 'sasrec'\n",
    "DATASET = 'ml20m'\n",
    "EXPERIMENT_NAME = 'baseline'\n",
    "SEED_FOLDER = 'other_seed'\n",
    "SPLIT_NAME = 'general'\n",
    "MODE = 'BASELINE'\n",
    "\n",
    "PROFILE_PATH_NAMES = None\n",
    "PREDEFINED_PARAMS = {'epochs': 200}\n",
    "# SEEDS = [42] if SEED_FOLDER == 'single_seed' else [1, 256]\n",
    "SEEDS = [1, 42, 256]\n",
    "\n",
    "with open('ml20m_baseline_all_runs.json') as f:\n",
    "    json_data = json.load(f)[:1]\n",
    "\n",
    "CONFIG_TEMPLATE_PATH = f'experiments-2_0/configs/{MODEL_NAME}/template/baseline.yaml'\n",
    "SAVE_FILE_TEMPLATE = '{hidden_units}-{num_blocks}-{num_heads}-{dropout_rate}-{learning_rate}-{seed}.yaml'\n"
   ],
   "id": "5b033f6f2e30f880",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T18:18:57.928082Z",
     "start_time": "2025-02-04T18:18:57.925312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# BASELINE MODE\n",
    "\n",
    "MODEL_NAME = 'sasrec'\n",
    "DATASET = 'amazon_m2'\n",
    "EXPERIMENT_NAME = 'baseline'\n",
    "SEED_FOLDER = 'other_seed'\n",
    "SPLIT_NAME = 'general'\n",
    "MODE = 'BASELINE'\n",
    "\n",
    "PROFILE_PATH_NAMES = None\n",
    "PREDEFINED_PARAMS = {'epochs': 30}\n",
    "SEEDS = [42] if SEED_FOLDER == 'single_seed' else [1, 256]\n",
    "\n",
    "with open('m2_baseline_all_runs.json') as f:\n",
    "    json_data = json.load(f)[:5]\n",
    "\n",
    "CONFIG_TEMPLATE_PATH = f'experiments-2_0/configs/{MODEL_NAME}/template/baseline_less_bs.yaml'\n",
    "SAVE_FILE_TEMPLATE = '{hidden_units}-{num_blocks}-{num_heads}-{dropout_rate}-{learning_rate}-{seed}.yaml'\n",
    "SBATCH_TEMPLATE_PATH = 'experiments-2_0/sbatch/BASE_BIG.sbatch'"
   ],
   "id": "a8e44f2b99fbba7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T09:19:55.588727Z",
     "start_time": "2025-01-27T09:19:55.585046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LLM MODE MULTI\n",
    "\n",
    "MODEL_NAME = 'sasrec'\n",
    "DATASET = 'beauty'\n",
    "EXPERIMENT_NAME = 'BEAUTY_INITIAL_MULTI'\n",
    "SEED_FOLDER = 'other_seed'\n",
    "SPLIT_NAME = 'general'\n",
    "MODE = 'LLM'\n",
    "\n",
    "# PROFILE_PATH_NAMES = ['gemma__large_multiple']\n",
    "\n",
    "PREDEFINED_PARAMS = {\n",
    "    'epochs': 25,\n",
    "    'hidden_units': 256,\n",
    "    'num_blocks': 2,\n",
    "    'num_heads': 2,\n",
    "    'dropout_rate': 0.2,\n",
    "    'learning_rate': 0.0005,\n",
    "}\n",
    "\n",
    "SEEDS = [42] if SEED_FOLDER == 'single_seed' else [1, 256]\n",
    "\n",
    "CONFIG_TEMPLATE_PATH = f'experiments-2_0/configs/{MODEL_NAME}/template/llm.yaml'\n",
    "SAVE_FILE_TEMPLATE = '{weighting_scheme}-{alpha}-{fine_tune_epoch}-{reconstruct_loss}-{reconstruction_layer}-{weight_scale}-{use_down_scale}-{use_upscale}-{multi_profile}-{multi_profile_aggr_scheme}-{scale_guide_loss}-{user_profile_embeddings_files}-{seed}.yaml'"
   ],
   "id": "9bb9feeaba4dc37",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# LLM MODE MULTI\n",
    "\n",
    "MODEL_NAME = 'sasrec'\n",
    "DATASET = 'beauty'\n",
    "EXPERIMENT_NAME = 'BEAUTY_INITIAL_MULTI'\n",
    "SEED_FOLDER = 'other_seed'\n",
    "SPLIT_NAME = 'general'\n",
    "MODE = 'LLM'\n",
    "\n",
    "# PROFILE_PATH_NAMES = ['gemma__large_multiple']\n",
    "\n",
    "PREDEFINED_PARAMS = {\n",
    "    'epochs': 25,\n",
    "    'hidden_units': 256,\n",
    "    'num_blocks': 2,\n",
    "    'num_heads': 2,\n",
    "    'dropout_rate': 0.2,\n",
    "    'learning_rate': 0.0005,\n",
    "}\n",
    "\n",
    "SEEDS = [42] if SEED_FOLDER == 'single_seed' else [1, 256]\n",
    "\n",
    "CONFIG_TEMPLATE_PATH = f'experiments-2_0/configs/{MODEL_NAME}/template/llm.yaml'\n",
    "SAVE_FILE_TEMPLATE = '{weighting_scheme}-{alpha}-{fine_tune_epoch}-{reconstruct_loss}-{reconstruction_layer}-{weight_scale}-{use_down_scale}-{use_upscale}-{multi_profile}-{multi_profile_aggr_scheme}-{scale_guide_loss}-{user_profile_embeddings_files}-{seed}.yaml'"
   ],
   "id": "9546550f0796b3f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T18:18:17.324207Z",
     "start_time": "2025-02-04T18:18:17.315136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LLM MODE MULTI\n",
    "\n",
    "MODEL_NAME = 'sasrec'\n",
    "DATASET = 'beauty'\n",
    "EXPERIMENT_NAME = 'BEAUTY_NORMAL2'\n",
    "SEED_FOLDER = 'other_seed'\n",
    "SPLIT_NAME = 'general'\n",
    "MODE = 'LLM'\n",
    "\n",
    "# PROFILE_PATH_NAMES = ['gemma__large_multiple']\n",
    "\n",
    "PREDEFINED_PARAMS = {\n",
    "    'epochs': 25,\n",
    "    'hidden_units': 128,\n",
    "    'num_blocks': 4,\n",
    "    'num_heads': 2,\n",
    "    'dropout_rate': 0.3,\n",
    "    'learning_rate': 0.0005,\n",
    "}\n",
    "\n",
    "SEEDS = [42, 1, 256]\n",
    "\n",
    "with open('best_kion.json') as f:\n",
    "    json_data = json.load(f)[:5]\n",
    "\n",
    "CONFIG_TEMPLATE_PATH = f'experiments-2_0/configs/{MODEL_NAME}/template/llm.yaml'\n",
    "SAVE_FILE_TEMPLATE = '{weighting_scheme}-{alpha}-{fine_tune_epoch}-{reconstruct_loss}-{reconstruction_layer}-{weight_scale}-{use_down_scale}-{use_upscale}-{multi_profile}-{multi_profile_aggr_scheme}-{scale_guide_loss}-{user_profile_embeddings_files}-{seed}.yaml'"
   ],
   "id": "319ed18c49977e36",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T09:26:27.033570Z",
     "start_time": "2025-02-03T09:26:27.027710Z"
    }
   },
   "cell_type": "code",
   "source": "json_data",
   "id": "8706bffe1025c4f7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'weighting_scheme': 'mean',\n",
       "  'alpha': 0.8,\n",
       "  'fine_tune_epoch': 6,\n",
       "  'reconstruct_loss': 'RMSE',\n",
       "  'reconstruction_layer': 1,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'False',\n",
       "  'use_upscale': 'True',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'False',\n",
       "  'user_profile_embeddings_files': 'gemma_short_large_umap_single'},\n",
       " {'weighting_scheme': 'exponential',\n",
       "  'alpha': 0.8,\n",
       "  'fine_tune_epoch': 8,\n",
       "  'reconstruct_loss': 'MSE',\n",
       "  'reconstruction_layer': 2,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'False',\n",
       "  'use_upscale': 'True',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'True',\n",
       "  'user_profile_embeddings_files': 'gemma_long_large_umap_single'},\n",
       " {'weighting_scheme': 'exponential',\n",
       "  'alpha': 0.65,\n",
       "  'fine_tune_epoch': 8,\n",
       "  'reconstruct_loss': 'RMSE',\n",
       "  'reconstruction_layer': 2,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'False',\n",
       "  'use_upscale': 'True',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'True',\n",
       "  'user_profile_embeddings_files': 'gemma_short_large_umap_single'},\n",
       " {'weighting_scheme': 'mean',\n",
       "  'alpha': 0.8,\n",
       "  'fine_tune_epoch': 6,\n",
       "  'reconstruct_loss': 'MSE',\n",
       "  'reconstruction_layer': 2,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'False',\n",
       "  'use_upscale': 'True',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'True',\n",
       "  'user_profile_embeddings_files': 'gemma_long_large_umap_single'},\n",
       " {'weighting_scheme': 'exponential',\n",
       "  'alpha': 0.5,\n",
       "  'fine_tune_epoch': 8,\n",
       "  'reconstruct_loss': 'RMSE',\n",
       "  'reconstruction_layer': 2,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'True',\n",
       "  'use_upscale': 'False',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'True',\n",
       "  'user_profile_embeddings_files': 'gemma_short_large_umap_single'},\n",
       " {'weighting_scheme': 'mean',\n",
       "  'alpha': 0.65,\n",
       "  'fine_tune_epoch': 6,\n",
       "  'reconstruct_loss': 'MSE',\n",
       "  'reconstruction_layer': 2,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'False',\n",
       "  'use_upscale': 'True',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'True',\n",
       "  'user_profile_embeddings_files': 'gemma_short_large_umap_single'},\n",
       " {'weighting_scheme': 'exponential',\n",
       "  'alpha': 0.65,\n",
       "  'fine_tune_epoch': 8,\n",
       "  'reconstruct_loss': 'RMSE',\n",
       "  'reconstruction_layer': 2,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'False',\n",
       "  'use_upscale': 'True',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'True',\n",
       "  'user_profile_embeddings_files': 'gemma_long_large_umap_single'},\n",
       " {'weighting_scheme': 'mean',\n",
       "  'alpha': 0.65,\n",
       "  'fine_tune_epoch': 8,\n",
       "  'reconstruct_loss': 'RMSE',\n",
       "  'reconstruction_layer': 2,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'True',\n",
       "  'use_upscale': 'False',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'True',\n",
       "  'user_profile_embeddings_files': 'gemma_short_large_umap_single'},\n",
       " {'weighting_scheme': 'exponential',\n",
       "  'alpha': 0.5,\n",
       "  'fine_tune_epoch': 8,\n",
       "  'reconstruct_loss': 'RMSE',\n",
       "  'reconstruction_layer': 2,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'True',\n",
       "  'use_upscale': 'False',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'True',\n",
       "  'user_profile_embeddings_files': 'gemma_long_large_umap_single'},\n",
       " {'weighting_scheme': 'exponential',\n",
       "  'alpha': 0.65,\n",
       "  'fine_tune_epoch': 6,\n",
       "  'reconstruct_loss': 'RMSE',\n",
       "  'reconstruction_layer': 1,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'False',\n",
       "  'use_upscale': 'True',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'True',\n",
       "  'user_profile_embeddings_files': 'gemma_short_large_umap_single'},\n",
       " {'weighting_scheme': 'mean',\n",
       "  'alpha': 0.5,\n",
       "  'fine_tune_epoch': 6,\n",
       "  'reconstruct_loss': 'MSE',\n",
       "  'reconstruction_layer': 1,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'False',\n",
       "  'use_upscale': 'True',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'False',\n",
       "  'user_profile_embeddings_files': 'gemma_long_large_umap_single'},\n",
       " {'weighting_scheme': 'mean',\n",
       "  'alpha': 0.65,\n",
       "  'fine_tune_epoch': 6,\n",
       "  'reconstruct_loss': 'MSE',\n",
       "  'reconstruction_layer': 2,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'False',\n",
       "  'use_upscale': 'True',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'False',\n",
       "  'user_profile_embeddings_files': 'gemma_long_large_umap_single'},\n",
       " {'weighting_scheme': 'mean',\n",
       "  'alpha': 0.5,\n",
       "  'fine_tune_epoch': 4,\n",
       "  'reconstruct_loss': 'RMSE',\n",
       "  'reconstruction_layer': 2,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'False',\n",
       "  'use_upscale': 'True',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'False',\n",
       "  'user_profile_embeddings_files': 'gemma_long_large_umap_single'},\n",
       " {'weighting_scheme': 'exponential',\n",
       "  'alpha': 0.8,\n",
       "  'fine_tune_epoch': 8,\n",
       "  'reconstruct_loss': 'RMSE',\n",
       "  'reconstruction_layer': 1,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'False',\n",
       "  'use_upscale': 'True',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'False',\n",
       "  'user_profile_embeddings_files': 'gemma_short_large_umap_single'},\n",
       " {'weighting_scheme': 'mean',\n",
       "  'alpha': 0.5,\n",
       "  'fine_tune_epoch': 8,\n",
       "  'reconstruct_loss': 'RMSE',\n",
       "  'reconstruction_layer': 1,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'False',\n",
       "  'use_upscale': 'True',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'False',\n",
       "  'user_profile_embeddings_files': 'gemma_short_large_umap_single'},\n",
       " {'weighting_scheme': 'exponential',\n",
       "  'alpha': 0.65,\n",
       "  'fine_tune_epoch': 8,\n",
       "  'reconstruct_loss': 'RMSE',\n",
       "  'reconstruction_layer': 1,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'False',\n",
       "  'use_upscale': 'True',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'True',\n",
       "  'user_profile_embeddings_files': 'gemma_short_large_umap_single'},\n",
       " {'weighting_scheme': 'mean',\n",
       "  'alpha': 0.8,\n",
       "  'fine_tune_epoch': 6,\n",
       "  'reconstruct_loss': 'MSE',\n",
       "  'reconstruction_layer': 1,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'False',\n",
       "  'use_upscale': 'True',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'False',\n",
       "  'user_profile_embeddings_files': 'gemma_short_large_umap_single'},\n",
       " {'weighting_scheme': 'exponential',\n",
       "  'alpha': 0.5,\n",
       "  'fine_tune_epoch': 8,\n",
       "  'reconstruct_loss': 'RMSE',\n",
       "  'reconstruction_layer': 2,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'False',\n",
       "  'use_upscale': 'True',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'False',\n",
       "  'user_profile_embeddings_files': 'gemma_short_large_umap_single'},\n",
       " {'weighting_scheme': 'exponential',\n",
       "  'alpha': 0.65,\n",
       "  'fine_tune_epoch': 8,\n",
       "  'reconstruct_loss': 'MSE',\n",
       "  'reconstruction_layer': 1,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'False',\n",
       "  'use_upscale': 'True',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'False',\n",
       "  'user_profile_embeddings_files': 'gemma_short_large_umap_single'},\n",
       " {'weighting_scheme': 'mean',\n",
       "  'alpha': 0.8,\n",
       "  'fine_tune_epoch': 8,\n",
       "  'reconstruct_loss': 'MSE',\n",
       "  'reconstruction_layer': 1,\n",
       "  'weight_scale': 0.1,\n",
       "  'use_down_scale': 'False',\n",
       "  'use_upscale': 'True',\n",
       "  'multi_profile': 'False',\n",
       "  'multi_profile_aggr_scheme': 'mean',\n",
       "  'scale_guide_loss': 'False',\n",
       "  'user_profile_embeddings_files': 'gemma_short_large_umap_single'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T21:46:52.373396Z",
     "start_time": "2025-02-01T21:46:52.364981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LLM MODE MULTI\n",
    "\n",
    "MODEL_NAME = 'sasrec'\n",
    "DATASET = 'kion_en'\n",
    "EXPERIMENT_NAME = 'KION_INITIAL'\n",
    "SEED_FOLDER = 'other_seed'\n",
    "SPLIT_NAME = 'general'\n",
    "MODE = 'LLM'\n",
    "\n",
    "# PROFILE_PATH_NAMES = ['gemma__large_multiple']\n",
    "\n",
    "PREDEFINED_PARAMS = {\n",
    "    'epochs': 20,\n",
    "    'hidden_units': 64,\n",
    "    'num_blocks': 4,\n",
    "    'num_heads': 4,\n",
    "    'dropout_rate': 0.2,\n",
    "    'learning_rate': 0.00075,\n",
    "}\n",
    "\n",
    "with open('best_kion.json') as f:\n",
    "    json_data = json.load(f)[:40]\n",
    "\n",
    "SEEDS = [42] if SEED_FOLDER == 'single_seed' else [1, 256]\n",
    "\n",
    "CONFIG_TEMPLATE_PATH = f'experiments-2_0/configs/{MODEL_NAME}/template/llm.yaml'\n",
    "SAVE_FILE_TEMPLATE = '{weighting_scheme}-{alpha}-{fine_tune_epoch}-{reconstruct_loss}-{reconstruction_layer}-{weight_scale}-{use_down_scale}-{use_upscale}-{multi_profile}-{multi_profile_aggr_scheme}-{scale_guide_loss}-{user_profile_embeddings_files}-{seed}.yaml'"
   ],
   "id": "eb1002a5c03a35ba",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T09:15:43.328501Z",
     "start_time": "2025-02-03T09:15:43.319914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LLM MODE MULTI\n",
    "\n",
    "MODEL_NAME = 'sasrec'\n",
    "DATASET = 'kion_en'\n",
    "EXPERIMENT_NAME = 'KION_NORMAL'\n",
    "SEED_FOLDER = 'other_seed'\n",
    "SPLIT_NAME = 'general'\n",
    "MODE = 'LLM'\n",
    "\n",
    "# PROFILE_PATH_NAMES = ['gemma__large_multiple']\n",
    "\n",
    "PREDEFINED_PARAMS = {\n",
    "    'epochs': 20,\n",
    "    'hidden_units': 64,\n",
    "    'num_blocks': 4,\n",
    "    'num_heads': 4,\n",
    "    'dropout_rate': 0.3,\n",
    "    'learning_rate': 0.0005,\n",
    "}\n",
    "\n",
    "with open('best_kion.json') as f:\n",
    "    json_data = json.load(f)[:20]\n",
    "\n",
    "SEEDS = [42, 1, 256]\n",
    "\n",
    "CONFIG_TEMPLATE_PATH = f'experiments-2_0/configs/{MODEL_NAME}/template/llm.yaml'\n",
    "SAVE_FILE_TEMPLATE = '{weighting_scheme}-{alpha}-{fine_tune_epoch}-{reconstruct_loss}-{reconstruction_layer}-{weight_scale}-{use_down_scale}-{use_upscale}-{multi_profile}-{multi_profile_aggr_scheme}-{scale_guide_loss}-{user_profile_embeddings_files}-{seed}.yaml'"
   ],
   "id": "cb9d9f37510d43f6",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T17:13:42.969285Z",
     "start_time": "2025-02-11T17:13:42.964857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LLM MODE MULTI\n",
    "\n",
    "MODEL_NAME = 'sasrec'\n",
    "DATASET = 'ml20m'\n",
    "EXPERIMENT_NAME = 'ML20M_LLM_FINAL'\n",
    "SEED_FOLDER = 'other_seed'\n",
    "SPLIT_NAME = 'general'\n",
    "MODE = 'LLM'\n",
    "\n",
    "# PROFILE_PATH_NAMES = ['gemma_short_large_umap_single']\n",
    "\n",
    "PREDEFINED_PARAMS = {\n",
    "    'epochs': 200,\n",
    "    'hidden_units': 256,\n",
    "    'num_blocks': 4,\n",
    "    'num_heads': 4,\n",
    "    'dropout_rate': 0.2,\n",
    "    'learning_rate': 0.00075,\n",
    "}\n",
    "\n",
    "\n",
    "CONFIG_PARAMS = {\n",
    "    'weighting_scheme': ['exponential'],\n",
    "    'alpha': [0.2, 0.4, 0.5],\n",
    "    'fine_tune_epoch': [30, 70],\n",
    "    'reconstruct_loss': ['MSE'],\n",
    "    'reconstruction_layer': [-1],\n",
    "    'weight_scale': [0.1],\n",
    "    'use_down_scale': [True],\n",
    "    'use_upscale': [False],\n",
    "    'multi_profile': [False],\n",
    "    'multi_profile_aggr_scheme': ['mean'],\n",
    "    'scale_guide_loss': [True],\n",
    "    'seed': [42, 1, 256],\n",
    "}\n",
    "\n",
    "# with open('best_ml20m.json') as f:\n",
    "#     json_data = json.load(f)[:40]\n",
    "\n",
    "SEEDS = [42, 1, 256]\n",
    "\n",
    "CONFIG_TEMPLATE_PATH = f'experiments-2_0/configs/{MODEL_NAME}/template/llm.yaml'\n",
    "SAVE_FILE_TEMPLATE = '{weighting_scheme}-{alpha}-{fine_tune_epoch}-{reconstruct_loss}-{reconstruction_layer}-{weight_scale}-{use_down_scale}-{use_upscale}-{multi_profile}-{multi_profile_aggr_scheme}-{scale_guide_loss}-{user_profile_embeddings_files}-{seed}.yaml'"
   ],
   "id": "31007b72d9edf2c8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T20:20:32.018827Z",
     "start_time": "2025-02-06T20:20:32.015409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LLM MODE MULTI\n",
    "\n",
    "MODEL_NAME = 'sasrec'\n",
    "DATASET = 'amazon_m2'\n",
    "EXPERIMENT_NAME = 'AMAZON_LLM'\n",
    "SEED_FOLDER = 'other_seed'\n",
    "SPLIT_NAME = 'general'\n",
    "MODE = 'LLM'\n",
    "\n",
    "# PROFILE_PATH_NAMES = ['gemma__large_multiple']\n",
    "\n",
    "PREDEFINED_PARAMS = {\n",
    "    'epochs': 20,\n",
    "    'hidden_units': 64,\n",
    "    'num_blocks': 2,\n",
    "    'num_heads': 8,\n",
    "    'dropout_rate': 0.2,\n",
    "    'learning_rate': 0.0005,\n",
    "}\n",
    "\n",
    "\n",
    "CONFIG_PARAMS = {\n",
    "    'weighting_scheme': ['exponential'],\n",
    "    'alpha': [0.8],\n",
    "    'fine_tune_epoch': [5, 10],\n",
    "    'reconstruct_loss': ['MSE', 'RMSE'],\n",
    "    'reconstruction_layer': [1],\n",
    "    'weight_scale': [0.1],\n",
    "    'use_down_scale': [False],\n",
    "    'use_upscale': [False],\n",
    "    'multi_profile': [False],\n",
    "    'multi_profile_aggr_scheme': ['mean'],\n",
    "    'scale_guide_loss': [True, False],\n",
    "    'seed': [42, 1, 256],\n",
    "    'user_profile_embeddings_files': ['gemma_short_large_single'],\n",
    "}\n",
    "\n",
    "# with open('best_ml20m.json') as f:\n",
    "#     json_data = json.load(f)[:40]\n",
    "\n",
    "# SEEDS = [42, 1, 256]\n",
    "\n",
    "CONFIG_TEMPLATE_PATH = f'experiments-2_0/configs/{MODEL_NAME}/template/llm.yaml'\n",
    "SAVE_FILE_TEMPLATE = '{weighting_scheme}-{alpha}-{fine_tune_epoch}-{reconstruct_loss}-{reconstruction_layer}-{weight_scale}-{use_down_scale}-{use_upscale}-{multi_profile}-{multi_profile_aggr_scheme}-{scale_guide_loss}-{user_profile_embeddings_files}-{seed}.yaml'"
   ],
   "id": "7247710215a86590",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T20:15:40.114538Z",
     "start_time": "2025-02-06T20:15:40.013795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "{'weighting_scheme': 'attention',\n",
    "  'alpha': 0.8,\n",
    "  'fine_tune_epoch': 70,\n",
    "  'reconstruct_loss': 'MSE',\n",
    "  'reconstruction_layer': 1,\n",
    "  'weight_scale': 0.1,\n",
    "  'use_down_scale': 'True',\n",
    "  'use_upscale': 'False',\n",
    "  'multi_profile': 'False',\n",
    "  'multi_profile_aggr_scheme': 'mean',\n",
    "  'scale_guide_loss': 'False',\n",
    "  'user_profile_embeddings_files': '/home/nseverin/generate_user_profiles/recsys-user-profiles/data/ml-20m/short_descriptions/ml-20m-gemma-short-e5-all-256.json',\n",
    "  'seed': 256}"
   ],
   "id": "b546aacd3697d8b9",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mjson_data\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'json_data' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fc570c93db9eefb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T09:07:34.945306Z",
     "start_time": "2025-02-03T09:07:34.941163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LLM MODE MULTI\n",
    "\n",
    "MODEL_NAME = 'sasrec'\n",
    "DATASET = 'ml20m'\n",
    "EXPERIMENT_NAME = 'ML20M_NORMAL'\n",
    "SEED_FOLDER = 'other_seed'\n",
    "SPLIT_NAME = 'general'\n",
    "MODE = 'LLM'\n",
    "\n",
    "# PROFILE_PATH_NAMES = ['gemma__large_multiple']\n",
    "\n",
    "PREDEFINED_PARAMS = {\n",
    "    'epochs': 100,\n",
    "    'hidden_units': 256,\n",
    "    'num_blocks': 4,\n",
    "    'num_heads': 8,\n",
    "    'dropout_rate': 0.2,\n",
    "    'learning_rate': 0.00075,\n",
    "}\n",
    "\n",
    "\n",
    "with open('best_ml20m.json') as f:\n",
    "    json_data = json.load(f)[:20]\n",
    "\n",
    "\n",
    "SEEDS = [42, 1, 256] \n",
    "# if SEED_FOLDER == 'single_seed' else [1, 256]\n",
    "\n",
    "CONFIG_TEMPLATE_PATH = f'experiments-2_0/configs/{MODEL_NAME}/template/llm.yaml'\n",
    "SAVE_FILE_TEMPLATE = '{weighting_scheme}-{alpha}-{fine_tune_epoch}-{reconstruct_loss}-{reconstruction_layer}-{weight_scale}-{use_down_scale}-{use_upscale}-{multi_profile}-{multi_profile_aggr_scheme}-{scale_guide_loss}-{user_profile_embeddings_files}-{seed}.yaml'"
   ],
   "id": "d57ed098f7ddd436",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T16:08:33.676424Z",
     "start_time": "2025-01-27T16:08:33.672980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LLM MODE + OTHER DIVISION\n",
    "\n",
    "MODEL_NAME = 'sasrec'\n",
    "DATASET = 'beauty'\n",
    "EXPERIMENT_NAME = 'BEAUTY_50_50_single_new'\n",
    "SEED_FOLDER = 'other_seed'\n",
    "SPLIT_NAME = 'history_70_30'\n",
    "MODE = 'LLM'\n",
    "\n",
    "# PROFILE_PATH_NAMES = ['gemma__large_multiple']\n",
    "\n",
    "PREDEFINED_PARAMS = {\n",
    "    'epochs': 25,\n",
    "    'hidden_units': 256,\n",
    "    'num_blocks': 2,\n",
    "    'num_heads': 2,\n",
    "    'dropout_rate': 0.2,\n",
    "    'learning_rate': 0.0005,\n",
    "}\n",
    "\n",
    "SEEDS = [1, 256, 42]\n",
    " \n",
    "CONFIG_TEMPLATE_PATH = f'experiments-2_0/configs/{MODEL_NAME}/template/llm.yaml'\n",
    "SAVE_FILE_TEMPLATE = '{weighting_scheme}-{alpha}-{fine_tune_epoch}-{reconstruct_loss}-{reconstruction_layer}-{weight_scale}-{use_down_scale}-{use_upscale}-{multi_profile}-{multi_profile_aggr_scheme}-{scale_guide_loss}-{user_profile_embeddings_files}-{seed}.yaml'"
   ],
   "id": "90f639377fa0b31a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:10:53.473152Z",
     "start_time": "2025-02-10T00:10:53.465892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ARTEFACT_PATH = f'results/{MODEL_NAME}/{DATASET}/{EXPERIMENT_NAME}/{SEED_FOLDER}'\n",
    "CONFIG_PATH = f'experiments-2_0/configs/{MODEL_NAME}/{DATASET}/{EXPERIMENT_NAME}/{SEED_FOLDER}'\n",
    "BASH_PATH = f'experiments-2_0/bash/{MODEL_NAME}/{DATASET}/{EXPERIMENT_NAME}/{SEED_FOLDER}'\n",
    "SBATCH_PATH = f'experiments-2_0/sbatch/{MODEL_NAME}/{DATASET}/{EXPERIMENT_NAME}/{SEED_FOLDER}'\n",
    "\n",
    "SAVE_CONFIG_FILE = os.path.join(CONFIG_PATH, SAVE_FILE_TEMPLATE)\n",
    "\n",
    "# creation of folders\n",
    "os.makedirs(ARTEFACT_PATH, exist_ok=True)\n",
    "os.makedirs(CONFIG_PATH, exist_ok=True)\n",
    "os.makedirs(BASH_PATH, exist_ok=True)\n",
    "os.makedirs(SBATCH_PATH, exist_ok=True)\n",
    "\n",
    "FILE_MAPPING = read_json(os.path.join(FILE_MAPPING_PATH, f'{DATASET}.json'))\n",
    "FILE_TO_EMB_NAME = {}\n",
    "for emb_name, emb_file in FILE_MAPPING[SPLIT_NAME]['user_profile_embeddings_files'].items():\n",
    "    if isinstance(emb_file, str):\n",
    "        FILE_TO_EMB_NAME[emb_file] = emb_name\n",
    "    elif isinstance(emb_file, list):\n",
    "        FILE_TO_EMB_NAME[tuple(emb_file)] = emb_name\n",
    "    else:\n",
    "        print(emb_file)\n",
    "        raise Exception()\n",
    "    \n",
    "\n",
    "# add to predefined params the values about dataset\n",
    "PREDEFINED_PARAMS.update({\n",
    "    'profile_train_sequences': FILE_MAPPING[SPLIT_NAME]['profile_train_sequences'],\n",
    "    'finetune_train_sequences': FILE_MAPPING[SPLIT_NAME]['finetune_train_sequences'],\n",
    "    'valid_sequences': FILE_MAPPING[SPLIT_NAME]['valid_sequences'],\n",
    "    'test_sequences': FILE_MAPPING[SPLIT_NAME]['test_sequences'],\n",
    "    'mappings': FILE_MAPPING[SPLIT_NAME]['mappings'],\n",
    "    'counts': FILE_MAPPING[SPLIT_NAME]['counts'],\n",
    "    'experiment_name': EXPERIMENT_NAME,\n",
    "})\n",
    "\n",
    "#--------------------"
   ],
   "id": "c6f0c91761a2e89b",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T20:20:40.868443Z",
     "start_time": "2025-02-06T20:20:40.859485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# all_config_params = generate_config_params(json_data)\n",
    "# N_CONFS_PER_BASH = 1\n",
    "# TIME_TO_TAKE = '0-23:0'\n",
    "# \n",
    "# print('Number of configs:', len(all_config_params))\n",
    "# print(len(create_list_of_lists(N_CONFS_PER_BASH, len(all_config_params))))"
   ],
   "id": "972af78d863256e6",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m all_config_params \u001B[38;5;241m=\u001B[39m generate_config_params(\u001B[43mjson_data\u001B[49m)\n\u001B[1;32m      2\u001B[0m N_CONFS_PER_BASH \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m      3\u001B[0m TIME_TO_TAKE \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m0-23:0\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'json_data' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d7d67f9adad5dd7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fd606639d9e93c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d78fdf61d36e0fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3dd136f4599922ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "74f64451dbe02bb5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ff952e4368a885b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T20:16:09.417238Z",
     "start_time": "2025-02-10T20:16:09.412122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LLM MODE MULTI\n",
    "\n",
    "MODEL_NAME = 'sasrec'\n",
    "DATASET = 'ml20m'\n",
    "EXPERIMENT_NAME = 'ML20M_Best_LLM4'\n",
    "SEED_FOLDER = 'other_seed'\n",
    "SPLIT_NAME = 'general'\n",
    "MODE = 'LLM'\n",
    "\n",
    "# PROFILE_PATH_NAMES = ['gemma__large_multiple']\n",
    "\n",
    "PREDEFINED_PARAMS = {\n",
    "    'epochs': 200,\n",
    "    'hidden_units': 256,\n",
    "    'num_blocks': 4,\n",
    "    'num_heads': 4,\n",
    "    'dropout_rate': 0.2,\n",
    "    'learning_rate': 0.00075,\n",
    "}\n",
    "\n",
    "all_config_params = [\n",
    "    # {'weighting_scheme': 'exponential',\n",
    "    #   'alpha': 0.8,\n",
    "    #   'fine_tune_epoch': 30,\n",
    "    #   'reconstruct_loss': 'MSE',\n",
    "    #   'reconstruction_layer': 1,\n",
    "    #   'weight_scale': 0.1,\n",
    "    #   'use_down_scale': 'True',\n",
    "    #   'use_upscale': 'False',\n",
    "    #   'multi_profile': 'False',\n",
    "    #   'multi_profile_aggr_scheme': 'mean',\n",
    "    #   'scale_guide_loss': 'False',\n",
    "    #   'user_profile_embeddings_files': '/home/nseverin/generate_user_profiles/recsys-user-profiles/data/ml-20m/short_descriptions/ml-20m-gemma-short-e5-all-256.json',\n",
    "    #   'seed': 42,\n",
    "    # },\n",
    "    {'weighting_scheme': 'exponential',\n",
    "      'alpha': 0.8,\n",
    "      'fine_tune_epoch': 30,\n",
    "      'reconstruct_loss': 'MSE',\n",
    "      'reconstruction_layer': 1,\n",
    "      'weight_scale': 0.1,\n",
    "      'use_down_scale': 'True',\n",
    "      'use_upscale': 'False',\n",
    "      'multi_profile': 'False',\n",
    "      'multi_profile_aggr_scheme': 'mean',\n",
    "      'scale_guide_loss': 'True',\n",
    "      'user_profile_embeddings_files': '/home/nseverin/generate_user_profiles/recsys-user-profiles/data/ml-20m/short_descriptions/ml-20m-gemma-short-e5-all-256.json',\n",
    "      'seed': 42,\n",
    "    },\n",
    "    # {'weighting_scheme': 'last_item',\n",
    "    #   'alpha': 0.8,\n",
    "    #   'fine_tune_epoch': 30,\n",
    "    #   'reconstruct_loss': 'MSE',\n",
    "    #   'reconstruction_layer': 1,\n",
    "    #   'weight_scale': 0.1,\n",
    "    #   'use_down_scale': 'True',\n",
    "    #   'use_upscale': 'False',\n",
    "    #   'multi_profile': 'False',\n",
    "    #   'multi_profile_aggr_scheme': 'mean',\n",
    "    #   'scale_guide_loss': 'False',\n",
    "    #   'user_profile_embeddings_files': '/home/nseverin/generate_user_profiles/recsys-user-profiles/data/ml-20m/short_descriptions/ml-20m-gemma-short-e5-all-256.json',\n",
    "    #   'seed': 42,\n",
    "    # },\n",
    "    {'weighting_scheme': 'last_item',\n",
    "      'alpha': 0.8,\n",
    "      'fine_tune_epoch': 30,\n",
    "      'reconstruct_loss': 'MSE',\n",
    "      'reconstruction_layer': 1,\n",
    "      'weight_scale': 0.1,\n",
    "      'use_down_scale': 'True',\n",
    "      'use_upscale': 'False',\n",
    "      'multi_profile': 'False',\n",
    "      'multi_profile_aggr_scheme': 'mean',\n",
    "      'scale_guide_loss': 'True',\n",
    "      'user_profile_embeddings_files': '/home/nseverin/generate_user_profiles/recsys-user-profiles/data/ml-20m/short_descriptions/ml-20m-gemma-short-e5-all-256.json',\n",
    "      'seed': 42,\n",
    "    }\n",
    "]\n",
    "\n",
    "# if SEED_FOLDER == 'single_seed' else [1, 256]\n",
    "\n",
    "CONFIG_TEMPLATE_PATH = f'experiments-2_0/configs/{MODEL_NAME}/template/llm.yaml'\n",
    "SAVE_FILE_TEMPLATE = '{weighting_scheme}-{alpha}-{fine_tune_epoch}-{reconstruct_loss}-{reconstruction_layer}-{weight_scale}-{use_down_scale}-{use_upscale}-{multi_profile}-{multi_profile_aggr_scheme}-{scale_guide_loss}-{user_profile_embeddings_files}-{seed}.yaml'"
   ],
   "id": "6020696a92faeef8",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T20:19:47.912062Z",
     "start_time": "2025-02-10T20:19:47.908065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LLM MODE MULTI\n",
    "\n",
    "MODEL_NAME = 'sasrec'\n",
    "DATASET = 'beauty'\n",
    "EXPERIMENT_NAME = 'BEAUTY_Best_LLM4'\n",
    "SEED_FOLDER = 'other_seed'\n",
    "SPLIT_NAME = 'general'\n",
    "MODE = 'LLM'\n",
    "\n",
    "# PROFILE_PATH_NAMES = ['gemma__large_multiple']\n",
    "\n",
    "PREDEFINED_PARAMS = {\n",
    "    'epochs': 25,\n",
    "    'hidden_units': 128,\n",
    "    'num_blocks': 4,\n",
    "    'num_heads': 2,\n",
    "    'dropout_rate': 0.3,\n",
    "    'learning_rate': 0.0005,\n",
    "}\n",
    "\n",
    "all_config_params = [\n",
    "    {'weighting_scheme': 'mean',\n",
    "      'alpha': 0.5,\n",
    "      'fine_tune_epoch': 12.0,\n",
    "      'reconstruct_loss': 'RMSE',\n",
    "      'reconstruction_layer': 1,\n",
    "      'weight_scale': 0.1,\n",
    "      'use_down_scale': 'True',\n",
    "      'use_upscale': 'False',\n",
    "      'multi_profile': 'False',\n",
    "      'multi_profile_aggr_scheme': 'mean',\n",
    "      'scale_guide_loss': 'True',\n",
    "      'user_profile_embeddings_files': '/home/nseverin/generate_user_profiles/recsys-user-profiles/data/amazon_beauty/short_embedding_amazon_beauty_UMAP-128.json',\n",
    "      'seed': 42,\n",
    "    },\n",
    "    # {'weighting_scheme': 'mean',\n",
    "    #   'alpha': 0.5,\n",
    "    #   'fine_tune_epoch': 12.0,\n",
    "    #   'reconstruct_loss': 'RMSE',\n",
    "    #   'reconstruction_layer': 1,\n",
    "    #   'weight_scale': 0.1,\n",
    "    #   'use_down_scale': 'True',\n",
    "    #   'use_upscale': 'False',\n",
    "    #   'multi_profile': 'False',\n",
    "    #   'multi_profile_aggr_scheme': 'mean',\n",
    "    #   'scale_guide_loss': 'False',\n",
    "    #   'user_profile_embeddings_files': '/home/nseverin/generate_user_profiles/recsys-user-profiles/data/amazon_beauty/short_embedding_amazon_beauty_UMAP-128.json',\n",
    "    #   'seed': 42,\n",
    "    # },\n",
    "    {'weighting_scheme': 'last_item',\n",
    "      'alpha': 0.5,\n",
    "      'fine_tune_epoch': 12.0,\n",
    "      'reconstruct_loss': 'RMSE',\n",
    "      'reconstruction_layer': 1,\n",
    "      'weight_scale': 0.1,\n",
    "      'use_down_scale': 'True',\n",
    "      'use_upscale': 'False',\n",
    "      'multi_profile': 'False',\n",
    "      'multi_profile_aggr_scheme': 'mean',\n",
    "      'scale_guide_loss': 'True',\n",
    "      'user_profile_embeddings_files': '/home/nseverin/generate_user_profiles/recsys-user-profiles/data/amazon_beauty/short_embedding_amazon_beauty_UMAP-128.json',\n",
    "      'seed': 42,\n",
    "    },\n",
    "    # {'weighting_scheme': 'last_item',\n",
    "    #   'alpha': 0.5,\n",
    "    #   'fine_tune_epoch': 12.0,\n",
    "    #   'reconstruct_loss': 'RMSE',\n",
    "    #   'reconstruction_layer': 1,\n",
    "    #   'weight_scale': 0.1,\n",
    "    #   'use_down_scale': 'True',\n",
    "    #   'use_upscale': 'False',\n",
    "    #   'multi_profile': 'False',\n",
    "    #   'multi_profile_aggr_scheme': 'mean',\n",
    "    #   'scale_guide_loss': 'False',\n",
    "    #   'user_profile_embeddings_files': '/home/nseverin/generate_user_profiles/recsys-user-profiles/data/amazon_beauty/short_embedding_amazon_beauty_UMAP-128.json',\n",
    "    #   'seed': 42,\n",
    "    # },\n",
    "]\n",
    "\n",
    "# if SEED_FOLDER == 'single_seed' else [1, 256]\n",
    "\n",
    "CONFIG_TEMPLATE_PATH = f'experiments-2_0/configs/{MODEL_NAME}/template/llm.yaml'\n",
    "SAVE_FILE_TEMPLATE = '{weighting_scheme}-{alpha}-{fine_tune_epoch}-{reconstruct_loss}-{reconstruction_layer}-{weight_scale}-{use_down_scale}-{use_upscale}-{multi_profile}-{multi_profile_aggr_scheme}-{scale_guide_loss}-{user_profile_embeddings_files}-{seed}.yaml'"
   ],
   "id": "e3b117ba32b8a62a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# LLM MODE MULTI\n",
    "\n",
    "MODEL_NAME = 'sasrec'\n",
    "DATASET = 'beauty'\n",
    "EXPERIMENT_NAME = 'BEAUTY_Best_LLM4'\n",
    "SEED_FOLDER = 'other_seed'\n",
    "SPLIT_NAME = 'general'\n",
    "MODE = 'LLM'\n",
    "\n",
    "# PROFILE_PATH_NAMES = ['gemma__large_multiple']\n",
    "\n",
    "PREDEFINED_PARAMS = {\n",
    "    'epochs': 25,\n",
    "    'hidden_units': 128,\n",
    "    'num_blocks': 4,\n",
    "    'num_heads': 2,\n",
    "    'dropout_rate': 0.3,\n",
    "    'learning_rate': 0.0005,\n",
    "}\n",
    "\n",
    "all_config_params = [\n",
    "    {'weighting_scheme': 'mean',\n",
    "      'alpha': 0.5,\n",
    "      'fine_tune_epoch': 12.0,\n",
    "      'reconstruct_loss': 'RMSE',\n",
    "      'reconstruction_layer': 1,\n",
    "      'weight_scale': 0.1,\n",
    "      'use_down_scale': 'True',\n",
    "      'use_upscale': 'False',\n",
    "      'multi_profile': 'False',\n",
    "      'multi_profile_aggr_scheme': 'mean',\n",
    "      'scale_guide_loss': 'True',\n",
    "      'user_profile_embeddings_files': '/home/nseverin/generate_user_profiles/recsys-user-profiles/data/amazon_beauty/short_embedding_amazon_beauty_UMAP-128.json',\n",
    "      'seed': 42,\n",
    "    },\n",
    "    # {'weighting_scheme': 'mean',\n",
    "    #   'alpha': 0.5,\n",
    "    #   'fine_tune_epoch': 12.0,\n",
    "    #   'reconstruct_loss': 'RMSE',\n",
    "    #   'reconstruction_layer': 1,\n",
    "    #   'weight_scale': 0.1,\n",
    "    #   'use_down_scale': 'True',\n",
    "    #   'use_upscale': 'False',\n",
    "    #   'multi_profile': 'False',\n",
    "    #   'multi_profile_aggr_scheme': 'mean',\n",
    "    #   'scale_guide_loss': 'False',\n",
    "    #   'user_profile_embeddings_files': '/home/nseverin/generate_user_profiles/recsys-user-profiles/data/amazon_beauty/short_embedding_amazon_beauty_UMAP-128.json',\n",
    "    #   'seed': 42,\n",
    "    # },\n",
    "    {'weighting_scheme': 'mean',\n",
    "      'alpha': 0.5,\n",
    "      'fine_tune_epoch': 12.0,\n",
    "      'reconstruct_loss': 'RMSE',\n",
    "      'reconstruction_layer': -1,\n",
    "      'weight_scale': 0.1,\n",
    "      'use_down_scale': 'True',\n",
    "      'use_upscale': 'False',\n",
    "      'multi_profile': 'False',\n",
    "      'multi_profile_aggr_scheme': 'mean',\n",
    "      'scale_guide_loss': 'True',\n",
    "      'user_profile_embeddings_files': '/home/nseverin/generate_user_profiles/recsys-user-profiles/data/amazon_beauty/short_embedding_amazon_beauty_UMAP-128.json',\n",
    "      'seed': 42,\n",
    "    },\n",
    "    {'weighting_scheme': 'mean',\n",
    "      'alpha': 0.5,\n",
    "      'fine_tune_epoch': 12.0,\n",
    "      'reconstruct_loss': 'RMSE',\n",
    "      'reconstruction_layer': -1,\n",
    "      'weight_scale': 0.1,\n",
    "      'use_down_scale': 'True',\n",
    "      'use_upscale': 'False',\n",
    "      'multi_profile': 'False',\n",
    "      'multi_profile_aggr_scheme': 'mean',\n",
    "      'scale_guide_loss': 'True',\n",
    "      'user_profile_embeddings_files': '/home/nseverin/generate_user_profiles/recsys-user-profiles/data/amazon_beauty/short_embedding_amazon_beauty_UMAP-128.json',\n",
    "      'seed': 42,\n",
    "    },\n",
    "    # {'weighting_scheme': 'last_item',\n",
    "    #   'alpha': 0.5,\n",
    "    #   'fine_tune_epoch': 12.0,\n",
    "    #   'reconstruct_loss': 'RMSE',\n",
    "    #   'reconstruction_layer': 1,\n",
    "    #   'weight_scale': 0.1,\n",
    "    #   'use_down_scale': 'True',\n",
    "    #   'use_upscale': 'False',\n",
    "    #   'multi_profile': 'False',\n",
    "    #   'multi_profile_aggr_scheme': 'mean',\n",
    "    #   'scale_guide_loss': 'False',\n",
    "    #   'user_profile_embeddings_files': '/home/nseverin/generate_user_profiles/recsys-user-profiles/data/amazon_beauty/short_embedding_amazon_beauty_UMAP-128.json',\n",
    "    #   'seed': 42,\n",
    "    # },\n",
    "]\n",
    "\n",
    "# if SEED_FOLDER == 'single_seed' else [1, 256]\n",
    "\n",
    "CONFIG_TEMPLATE_PATH = f'experiments-2_0/configs/{MODEL_NAME}/template/llm.yaml'\n",
    "SAVE_FILE_TEMPLATE = '{weighting_scheme}-{alpha}-{fine_tune_epoch}-{reconstruct_loss}-{reconstruction_layer}-{weight_scale}-{use_down_scale}-{use_upscale}-{multi_profile}-{multi_profile_aggr_scheme}-{scale_guide_loss}-{user_profile_embeddings_files}-{seed}.yaml'"
   ],
   "id": "1f8ec9cb23ab3cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T20:19:52.555572Z",
     "start_time": "2025-02-10T20:19:52.548752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ARTEFACT_PATH = f'results/{MODEL_NAME}/{DATASET}/{EXPERIMENT_NAME}/{SEED_FOLDER}'\n",
    "CONFIG_PATH = f'experiments-2_0/configs/{MODEL_NAME}/{DATASET}/{EXPERIMENT_NAME}/{SEED_FOLDER}'\n",
    "BASH_PATH = f'experiments-2_0/bash/{MODEL_NAME}/{DATASET}/{EXPERIMENT_NAME}/{SEED_FOLDER}'\n",
    "SBATCH_PATH = f'experiments-2_0/sbatch/{MODEL_NAME}/{DATASET}/{EXPERIMENT_NAME}/{SEED_FOLDER}'\n",
    "\n",
    "SAVE_CONFIG_FILE = os.path.join(CONFIG_PATH, SAVE_FILE_TEMPLATE)\n",
    "\n",
    "# creation of folders\n",
    "os.makedirs(ARTEFACT_PATH, exist_ok=True)\n",
    "os.makedirs(CONFIG_PATH, exist_ok=True)\n",
    "os.makedirs(BASH_PATH, exist_ok=True)\n",
    "os.makedirs(SBATCH_PATH, exist_ok=True)\n",
    "\n",
    "FILE_MAPPING = read_json(os.path.join(FILE_MAPPING_PATH, f'{DATASET}.json'))\n",
    "FILE_TO_EMB_NAME = {}\n",
    "for emb_name, emb_file in FILE_MAPPING[SPLIT_NAME]['user_profile_embeddings_files'].items():\n",
    "    if isinstance(emb_file, str):\n",
    "        FILE_TO_EMB_NAME[emb_file] = emb_name\n",
    "    elif isinstance(emb_file, list):\n",
    "        FILE_TO_EMB_NAME[tuple(emb_file)] = emb_name\n",
    "    else:\n",
    "        print(emb_file)\n",
    "        raise Exception()\n",
    "    \n",
    "\n",
    "# add to predefined params the values about dataset\n",
    "PREDEFINED_PARAMS.update({\n",
    "    'profile_train_sequences': FILE_MAPPING[SPLIT_NAME]['profile_train_sequences'],\n",
    "    'finetune_train_sequences': FILE_MAPPING[SPLIT_NAME]['finetune_train_sequences'],\n",
    "    'valid_sequences': FILE_MAPPING[SPLIT_NAME]['valid_sequences'],\n",
    "    'test_sequences': FILE_MAPPING[SPLIT_NAME]['test_sequences'],\n",
    "    'mappings': FILE_MAPPING[SPLIT_NAME]['mappings'],\n",
    "    'counts': FILE_MAPPING[SPLIT_NAME]['counts'],\n",
    "    'experiment_name': EXPERIMENT_NAME,\n",
    "})\n",
    "\n",
    "#--------------------"
   ],
   "id": "120a8c91061f6380",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T20:20:07.575581Z",
     "start_time": "2025-02-10T20:20:07.573126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "N_CONFS_PER_BASH = 1\n",
    "TIME_TO_TAKE = '0-23:0'\n",
    "\n",
    "print('Number of configs:', len(all_config_params))\n",
    "print(len(create_list_of_lists(N_CONFS_PER_BASH, len(all_config_params))))"
   ],
   "id": "8def550089be8a59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of configs: 2\n",
      "2\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T20:20:08.352421Z",
     "start_time": "2025-02-10T20:20:08.348418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "create_config_files(all_config_params)\n",
    "create_bash_files(all_config_params, n_confs_per_bash=N_CONFS_PER_BASH)\n",
    "create_sbatch_files()"
   ],
   "id": "aacb7ca249cbd439",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nseverin/generate_user_profiles/recsys-user-profiles/data/amazon_beauty/short_embedding_amazon_beauty_UMAP-128.json\n",
      "-------\n",
      "/home/nseverin/generate_user_profiles/recsys-user-profiles/data/amazon_beauty/short_embedding_amazon_beauty_UMAP-128.json\n",
      "-------\n",
      "2\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T20:20:13.721631Z",
     "start_time": "2025-02-10T20:20:13.718736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for file in os.listdir(SBATCH_PATH):\n",
    "    print('sbatch', SBATCH_PATH+'/'+file)"
   ],
   "id": "6c7edf6c22cc534a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbatch experiments-2_0/sbatch/sasrec/beauty/BEAUTY_Best_LLM4/other_seed/1-1.sbatch\n",
      "sbatch experiments-2_0/sbatch/sasrec/beauty/BEAUTY_Best_LLM4/other_seed/0-0.sbatch\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ef4322557d7c76ed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
