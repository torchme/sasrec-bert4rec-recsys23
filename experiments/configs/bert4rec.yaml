# experiments/configs/bert4rec.yaml

model:
  type: BERT4Rec
  params:
    num_layers: 4                # Количество слоёв трансформера
    hidden_size: 256             # Размер скрытого слоя
    num_heads: 4                 # Количество голов внимания
    dropout_rate: 0.3            # Уровень dropout
    max_seq_length: 100          # Максимальная длина последовательности
    item_embedding_dim: 256      # Размерность эмбеддинга предметов
    position_embedding: true     # Использовать позиционные эмбеддинги
    mask_probability: 0.15       # Вероятность маскировки для обучения

training:
  epochs: 100
  batch_size: 128
  learning_rate: 0.0005
  optimizer: AdamW
  weight_decay: 0.01
  scheduler:
    type: CosineAnnealingLR
    T_max: 50
  loss_function: CrossEntropyLoss
  gradient_clip: 5.0

data:
  dataset_path: data/dataset.csv  # Путь к датасету
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  shuffle: true

logging:
  log_dir: logs/bert4rec
  save_checkpoint: true
  checkpoint_path: checkpoints/bert4rec.pth
  save_best_only: true

seed: 42
